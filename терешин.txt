РЕФЕРАТ
 
На 53 c., 18 рисунков, 3 таблицы, 4 приложения
КЛЮЧЕВЫЕ СЛОВА: МЕДИЦИНСКАЯ ДИАГНОСТИКА, ЛЕГКИЕ, ГЛУ­ БОКОЕ ОБУЧЕНИЕ, ВЕБ-ПРИЛОЖЕНИЕ.
Тема выпускной квалификационной работы: «Разработка веб-приложения бинарной классификации пациентов на основании снимка цифрового рентгена лег­ ких».
В данной работе изложены методы цифровой обработки рентгенограмм легких, применяемые при создании вспомогательных систем медицинской диа­ гностики. Даны общие понятия и рассмотрены основные методы классификации рентгеновских снимков, проведен их анализ и определен наиболее эффективный из них. Изучено устройсво и принцип работы сверточных нейронных сетей в задаче выявления патологий на цифровых изображениях легких, разработана модель би­ нарной классификации с использованием глубокого обучения. Для взаимодействия с полученным классификатором была разработана конкретная программная реали­ зация веб-приложения для определения здоровых рентгенограмм и изображений легких с признаками патологии.
 
 
ВВЕДЕНИЕ
 
Легкие человека, являясь важной составной частью дыхательной системы, в значительной степени подвержены поражениям в результате воздействия экологи­ ческих, биологических и других факторов. Миру уже известно большое количество различных заболеваний органов нижних дыхательных путей. В наши дни методы лучевой диагностики являются наиболее распространенными в практическом здравоохранении, позволяя неинвазивно исследовать состояние органов дыхания и тканей.
В медицинских учреждениях общего профиля именно цифровое рентге­ нологическое исследование органов грудной клетки является первым методом для большинства рутинных медицинских осмотров и скрининга респираторных заболеваний. Анализ большого количества таких изображений в течение рабочего дня – утомительная задача, требующая большого количества времени специалиста.
Ситуацию заметно обострило наступление в 2020 году пандемии COVID-19 [18], которая продолжает оказывать разрушительное воздействие на здоровье и благополучие населения всего мира. В значительной степени поражая нижние дыхательные пути, инфекция многократно увеличила количество проведенных рентгенологических исследований легких и дополнительно повысила нагрузку на врачей.
Таким образом, нехватка медицинских работников, способных выполнить анализ рентгеновских снимков с целью выявления патологий с большой надежно­ стью и за малое время является серьезной проблемой.
Целью данной работы является создание автоматизированной системы вспо­ могательной диагностики, способной производить анализ получаемых цифровых снимков грудной клетки на предмет наличия патологий и в соответствии с результа­ тами анализа осуществлять бинарную классификацию, распределяя изображения на две группы: «норма» и «патология».
Актуальность исследования подтверждается отсутствием широко распро­ страненных аналогов таких систем в России и мире.
Объектом исследования является программное обеспечение медицинских систем.
Предмет исследования – системы поддержки принятия решений, в частности системы автоматизированного обследования и вспомогательной диагностики рентгенограмм грудной клетки.

В ходе исследования были поставлены и выполнены следующие задачи:
1.    Изучить технологии обработки цифровых изображений легких.
2.    Разработать модель бинарной классификации легких.
3.    Разработать веб-приложение для взаимодействия с полученной моделью.
4.    Протестировать полученные результаты на реальных рентгенограммах.
5.    Проанализировать полученные результаты с целью улучшения и дополне­ ния.

ГЛАВА 1. АНАЛИЗ ПРЕДМЕТНОЙ ОБЛАСТИ
 
Для успешного решения задачи построения автоматизированной системы вспомогательной диагностики, в первую очередь, необходимо провести анализ существующих методов обработки и анализа рентгенограмм грудной клетки с целью выявления наиболее подходящей технологии. Выявление патологий на снимке легких является комплексной задачей, которую в общем случае можно представить в виде следующей последовательности этапов: фильтрация изобра­ жения; предварительная обработка; сегментация; распознавание; диагностика. В данной главе определены общие положения и проблемы цифровой диагностики легких, представлены основные существующие способы решения на каждой из упомянутых стадий, а также принято решение о выборе наиболее подходящего из методов.
 
1.1.  Описание проблем цифровой диагностики патологий легких
 
Рентгенография - очень точный, информативный метод диагностики забо­ леваний, позволяющий увидеть даже самые незначительные изменения в ткани легких. В настоящее время активно происходит вытеснение флюорографии как вида исследования, в результате чего в подавляющем большинстве пациентам назначается цифровой рентген грудной клетки. Так, снимок представляет собой более детальное и большое растровое изображение, хранимое на физических но­ сителях. В память записывается матрица изображения, в которой каждый элемент
– это значение яркости серого его определенного пикселя (от полностью черного до полностью белого цвета).
Интенсивность оттенка зависит от плотности тканей, через которые проходят рентгеновские лучи. В здоровых легких легочные поля не имеют включений в виде теней различной формы и размеров, они однородны, в них не различимо деление на сегменты. Участки, в которых плотность тканей отлична от нормальной могут сигнализировать о нарушении структуры и появлении целого ряда заболеваний. В общем случае выделяют следующие рентгенологические проявления легочной патологии: затенения легких; просветления легких; изменения легочного рисунка; изменения корней легкого [3] Обширные затенения и просветления легких представлены на рис.1.1. Именно на основе наличия таких симптомов и синдромов

должно приниматься решение о результате классификации врачом-специалистом или автоматизированной системой.
a)                                                                                                                                                                                                                                         


b)
 
 
 
 
 
 
 
Рис.1.1. Обзорные рентгенограммы ОГК [4]: a — синдром обширного затенения; b — синдром обширного просветления. Везикулярная диффузная эмфизема легких
 
Следует отметить, что определение патологий на изображениях является сложной задачей в области цифровой обработки медицинских изображений, так как место, расположение, форма и размер возможных отклонений являются непредсказуемыми факторами. Задачу усложняет и тот факт, что сами по себе рентгенологические снимки не обладают большим контрастом и характеризуются наличием шумов — участками с более низкими показателями яркости пикселей, на что влияет ряд факторов: напряжение в рентгеновской трубке, различные аппаратные ограничения, человеческий факто, габариты пациента и др. Это снижает
«визуальную различимость» новообразований, что может привести к потере важных данных о состоянии органов или к полной непригодности изображения. Тем не менее, если шум носит локальный и ограниченный характер, улучшить качество снимка и соответственно качество классификации могут методы предобработки цифровых рентгеновских изображений.
 
1.2.                                                 Методы первичной обработки рентгенограмм
 
Предобработка изображения востребована по причине сложности задачи классификации и высоким требованиям к уровню доверия используемых техноло­ гий. Такие процедуры решают следующие задачи:
–    подавление шума;
–    контрастное усиление;
–    исправление отсутствующих или неправильных значений определенных пикселей;

–    оптимальная обработка данных для дальнейших задач;
–    устранение различных артефактов.
Существует большое количество доступных методов, применяемых для улуч­ шения визуального восприятия и качества полученных изображений. В их числе улучшение краев, подавление шума или эквализация гистограммы интенсивности пикселей. Помимо этого, одним из наиболее простых, но в то же время эффектив­ ных алгоритмов является усиление локального контраста (рис.1.2). Общее решение имеет вид 1.1.
 

 
𝐿𝐿𝐶𝐸

= √︁

𝐿 − 𝐿′
𝐿2 − (𝐿′)2

,                                                   (1.1)

где L – исходное изображение, а 𝐿′ - изображение, к которому применено размытие Гаусса.





Рис.1.2. Примеры работы метода услиения локального контраста [2]
 
 
1.3.  Методы сегментации легких на рентгеновских изображениях
 
Среди процессов предварительной обработки сегментация изображений играет важную роль для извлечения полезных признаков в задачах классификации. Очевидным фактом является то, что области снимка вне организма человека, находящиеся по краям рентгенограммы никаким образом не влияют на результат постановки диагноза в рамках скрининга. Ключевой функцией сегментации явля­ ется деление изображения на сегменты – части, в которых все пиксели, имеющие схожие значения интенсивности, получают одинаковые метки и соответственно относятся к одному классу. Целью такой процедуры может являться упрощение представления изображения, выделение необходимых объектов желаемой части исходного изображения или скрытие нежелательных областей или поверхностей.

Сегментация может применяться во многих областях предобработки, таких как распознавание объекта, окклюзия объекта, оценка границы, защита или сжатие изображений и т. д. В медицинской диагностике данный метод может применяться, как частный случай, в задачах обнаружения крупных узелков и различных образо­ ваний. Особенно это актуально при выявлении опухолей на основании снимков МРТ мозга [1]. В общем же случае он может применяться главным образом для выделения контура легких или их отделение от сердца [8]. В данном разделе представлены основные из используемых подходов.
1.3.1.  Методы сегментации легких на рентгеновских изображениях
 
Метод на основе разбиения графа (англ.graph-cut) используется для нахож­ дения глобально оптимальной сегментации N-мерного изображения [6]. Основная идея заключается в сопоставлении изображения некоторому графу – структуре данных, используемой для моделирования попарных отношений между объектами из определенного набора. В данном случае объектами выступают пиксели изобра­ жения, а их отношения выражаются в виде определенной зависимости между их свойствами. Решение такой задачи сводится к решению оптимизационной задачи, которая учитывает свойства границ легкого. В результате находится наилучшее разбиение графа на подграфы, в результате которого получается отделить внешнюю часть рентгенограммы (фон) от внутреннего объекта (легких) [17].
Однако, из-за слабой устойчивости к шумам такой подход не используется в чистом виде, а применяется только для уточнения границ сегментации. На первом этапе используется модель легкого, которая представляет собой среднюю форму легкого из выбранных обучающих масок. Сами маски вычисляется с помощью по­ иска похожих уже отсегментированных изображений легких следующим образом: сначала все доступные наборы линейно выравниваются по заданному входному изображению рентгена. Затем вычисляются вертикальная и горизонтальная про­ екции по гистограмме интенсивности пикселей. На последнем этапе на основе определенных коэффициентов происходит измерение сходства между входным и обучаемым изображениями. Когда удается определить примерную выделенную форму области, все границы уточняются с использованием алгоритма разделения графа.
Несмотря на высокую скорость такого подхода, недостатками является необходимость в хранении готового набора масок легких и получении статической

модели формы. Другими словами, различные вращения или изменения масштаба снимков заметно уменьшат точность выделения, в результате которой некоторые пограничные области, потенциально способные нести информацию о заболевании, будут утеряны.
 
1.3.2.  Пороговый метод Оцу
 
Группа пороговых методов сегментации позволяет определять принадлеж­ ность пикселей к объекту или фону в зависимости от того, превышает ли их значение яркости определяемое значение, называемое порогом T. Такие методы отличаются только реализацией алгоритма, позволяющего вычислять этот порог в изображении. Наиболее быстрым и эффективным является метод, предложенный японским ученым Нобуюки Оцу [14].
Суть предложенного алгоритма заключается в анализе гистограммы яркости изображения и минимизации внутриклассовой дисперсии, что означает максими­ зацию межклассовой дисперсии. В результате единственного обхода гистограммы получается определить оптимальное значение T, которое разделяет объект от фона.
Безусловными достоинствами данного метода являются быстрое время выполнения и высокая адаптивность к различного рода снимкам, однако он обладает существенными недостатками. Прежде всего, это чувствительность к неравномерной яркости изображения. Такой подход эффективно показывает свою работу, например, для выделения черного текста на светлом листе бумаги, но рентгенограмма легких – более сложное изображение, в котором не всегда удается точно выделить границы легких даже глазу человека. Решением может служить переход к вычислению не глобального порога, определяемого для всего снимка, а к определению нескольких локальных значений T или к адаптивной пороговой сегментации, где дополнительно учитываются координаты пикселей. В таком случае возникают дополнительные комплексные задачи для выделения всех промежуточных областей.
1.3.3.  Метод морфологического водораздела
 
Данный метод основан на представлении изображения в виде трехмерной поверхности, где в качестве третьей координаты (высоты точки над горизонтальной плоскостью) берут уровень яркости пикселя. Если полученную поверхность «за­

полнить водой», то участки с наименьшей яркостью пикселей будут образовывать бассейны.
Процесс сегментации начинается с определения некоторых региональных минимумов, которые определяют местонахождение самых низких точек области, куда будет «стекать вода». Далее путем измерения и сопоставления расстояний до этих минимумов для всех точек вся исследуемая область разбивается на бассейны. Пиксель будет отнесен к тому региону, расстояние до минимума которого является наименьшим. Места объединения бассейнов отмечаются как линии водораздела. Алгоритм производит вычисления до тех пор, пока не останется неотмеченных точек на всех линиях водораздела.
В чистом виде данный метод осуществляет избыточную сегментацию, про­ исходит выделение огромного числа областей, вызванных шумами и локальными неровностями. В медицинской диагностике алгоритм способен показывать хоро­ шие результаты при детектировании патологий на снимках мозга. Тем не менее, одна из модификаций метода, подход Watersnake, был использован в работе [11] для настройки гладкости границ регионов и выделении области легких на рент­ генологических снимках. Автором отмечается, что из-за особенностей строения человеческого организма правый купол диафрагмы располагается несколько выше левого. Как следствие, выделенная часть левого легкого оказалась слегка суже­ ной, что требует регулировки для получения границы, более близкой к истинной. Подробное сравнение метода водораздела с пороговым методом Оцу в задачах сегментации рентгенологических изображений грудной клетки описано в работе [12].
 
1.4.  Методы классификации рентгенограмм
 
Методы классификации отвечают за последний этап решения задачи вы­ явления патологий – распознавание и диагностика. Данная группа представлена алгоритмами машинного обучения (МО), которые относятся к типу обучения с учителем (контролируемое обучение). Это значит, что такие модели использу­ ют заранее подготовленный размеченный набор данных (обучающая выборка), с помощью которого и осуществляют прогнозирование. При анализе цифровых рентгенограмм грудной клетки используются следующие подходы.

1.4.1.  Решающие деревья и случайный лес
 
Используемые деревья решений представляют собой комбинаций узлов и вет­ вей. В промежуточных узлах условия, на основе которых получается эффективно разделить поступающую выборку на классы, используя критерии информативно­ сти. В результате ветвления в конечных листах оказываются классы, которые им приписаны. Сами условия на каждом из этапов определяются жадным способом, то есть выбирается наилучшее на данный момент разбиение объектов выборки.
Рентгенографические изображения, которые включают узелки в легких, сильно различаются по распределению интенсивности пикселей от здоровых снимков. Поэтому классификатор на основе дерева решений, анализируя все входные пиксели, способен с высокой точностью классифицировать снимки. Тем не менее, для выявления более сложных с точки зрения выявления патологий (например, инфекционных заболеваний) при использовании данного подхода требуют дополнительных преобразований и вычислений. Так, для диагностики туберкулеза возможным решением является предварительное выделение еще одной дополнительной характеристики снимка – туберкулезного индекса, который применяется рентгенологами в процессе их ежедневного скрининга.
Построение некоторого количества независимых деревьев с последующим усреднением полученных результатов является методом, называемым случайным лесом. Как правило, он способен демонстрировать наиболее высокие показатели точности и является признанным классификатором.
1.4.2.  Метод опорных векторов
 
Метод опорных векторов (англ. SVM, Support Vector Machine), который фак­ тически являлся стандартным методом классификации до конца 2000-х годов, основан на построении разделяющей гиперплоскости в многомерном пространстве признаков объектов, представляемых пикселями изображения. Основная цель обучения SVM – найти оптимальную функцию-разделитель, называемую клас­ сификатором. Отличительной особенностью данного подхода является то, что гиперплоскость вычисляется с наибольшим запасом, то есть гиперплоскость с максимальным зазором – расстоянием до ближайшей точки обучающих данных любого класса. В идеальных условиях векторы признаков снимков с патологиями будут иметь расстояние до разделяющей гиперплоскости одного знака, а векто­

ры признаков здоровых рентгенограмм – противоположного знака. Причем чем больше расстояние, тем больше уверенность в классификации.
Данный подход используется в качестве мощного инструмента для задач регрессии и классификации и до недавнего времени часто использовался для распознавания объектов, в том числе и для определения туберкулезных бактерий на рентгенограммах. Известны исследования, где происходит сравнение всех классификационных подходов МО для решения и более частной задачи – выявления инфекции COVID-19 на цифровых снимках легких [5].
1.4.3.  Классификация с использованием нейронных сетей
 
В связи с ростом вычислительных мощностей компьютеров, широким рас­ пространением сравнительно дешевых графических многоядерных ускорителей и накоплением больших баз изображений в различных предметных областях, стало возможным использование глубоких нейронных сетей (НС) для решения широкого круга прикладных задач, в частности для анализа рентгенограмм и определения факта наличия заболеваний у человека. Несомненно, в последние 10 лет этот метод является наиболее подходящим инструментом для использования в различ­ ных автоматизированных медицинских системах поддержки принятия решений. Это подтверждают многочисленные исследования, в которых нейронные сети добиваются наиболее высоких результатов, поскольку могут описывать сложные нелинейные зависимости высокого порядка.
Существенным достоинством является также и тот факт, что НС способны проводить как самостоятельную классификацию изображений без предваритель­ ной обработки, так и использоваться в качестве технологий для проведения предыдущих этапов решения задачи, например для сегментации легких [Unet] или выделении и локализации пораженной области на снимке [10]. В последнем случае такие системы не классифицируют, а осуществляют помощь в скрининге медицинским работникам.
Высокая точность диагностики, универсальность применения и отсутствие в необходимости предварительных сложных операций по цифровой обработке изображений послужили причиной выбора данного подхода в работе в качестве модели классификации аномалий на рентгенограммах грудных клеток. Основным требованием для успешного построения готовой структуры является наличие большого количества данных для обучения – базы размеченных рентгеновских

изображений легких. Описание подбора базы, а также общие принципы построения нейронных сетей описаны в следующих главах.
 
1.5.  Выводы
 
Потребность в создании автоматизированных средств диагностирования и анализа медицинских снимков существует в течение продолжительного количества времени. С конца 20-го века для решения данной задачи использовались и продол­ жают использоваться различные технологии цифровой обработки, аналитические методы сегментации и алгоритмы так называемого классического машинного обучения. Тем не менее, в то время существовала проблема ограниченности вы­ числительных мощностей, поэтому все используемые подходы составлялись с поправкой на это. В настоящее время, когда производительность главных ком­ плектующих компьютеров за годы увеличивается в несколько раз, на протяжении 10 лет небывалой популярностью пользуются различные архитектуры нейронных сетей, показывающие лучшие показатели точности.
В результате изучения исследований по данной теме был получен материал, анализ которого позволил заключить, что НС – подходящий вариант для реше­ ния задачи классификации снимков цифрового рентгена. Вместе с тем следует подчеркнуть, что альтернативные методы решения не являются устаревшими и малоэффективными. Напротив, комбинация или совместное использование НС и, например, методов сегментации для выделения областей, представляющих интерес, способны только улучшить показатели эффективности выявления аномалий легких [2].
 
 
ГЛАВА 2. ТЕОРЕТИЧЕСКАЯ ЧАСТЬ
 
2.1.                                 Формальное описание задачи бинарной классификации
 
Бинарная классификация является распространенной задачей в машинном обучении. По своей сути она включает в себя прогнозирование принадлежности произвольного примера к тому или иному классу. Термин «бинарная» ограничивает количество возможных классов до двух, поскольку в данной работе определяется только наличие патологии, которое может описываться состояниями «присут­

ствует» или «отсутствует». Формально задачу классификации можно описать следующим образом.
Пусть 𝑋   = {𝑥1,𝑥2,...𝑥𝑘 } – множество объектов, а 𝑌   = {0,1} – конечное
множество классов. Чаще всего классу, представляющему интерес (присутствие
заболевания) присваивается метка 1. Решить задачу означает подобрать оптималь­ ную функцию 𝑎 (𝑥) наилучшим образом осуществляющую отображение 𝑦∗ : 𝑋 → 𝑌 Она должна подчерпнуть ключевые закономерности, позволяющими правильно классифицировать все объекты.
Каждый объект задается описанием 𝑥𝑖 = (𝑥1,𝑥2,..𝑥𝑛)𝑖 – определенным набо­ ром характеристик, на основе которых и определяется принадлежность к тому
или иному классу. Если признаки объекта являются вещественными числами, тогда каждый объект может быть представлен как точка n-мерного евклидового пространства. Полученный алгоритм должен наилучшим образом аппроксимиро­ вать разделяющую гиперплоскость в пространстве этих признаков, позволяющих отделить объекты одного класса от другого. При размерности n=2 такая ситуация имеет вид, изображенный на рис.2.1.
 





 
Рис.2.1. Разделяющая область классификатора
 
Классификация относится к группе задач обучения с учителем. Это значит, что для обучения модели используется множество пар объект-ответ 𝑍 = {𝑥𝑖 : 𝑦𝑖 }𝑘 , называемое обучающей выборкой. Ответы – известные классовые принадлежности для всех объектов из 𝑍. В результате обучения полученный алгоритм должен с

желаемой точностью определять метку класса для произвольного 𝑥 𝑗 , не входящего в эту выборку.
Кроме того, для построения нашей модели после получения результатов функции на обучающей выборке нам необходимо определять, насколько точ­
но и правильно на текущий момент алгоритм 𝑎 (𝑥) расставляет метки классов.
Такая задача достигается введением функции ошибки (функции потерь) 𝑄, ко­ торая измеряет отклонение вычисленных  𝑦′𝑖   от реальных  𝑦𝑖  на нашей выборке
𝑄(𝑎 (𝑥),𝑍). Одной из самых популярных функций ошибки, например, является
среднеквадратичная ошибка (англ. MSE, Mean Squared Error) (2.1).
 
𝑀𝑆𝐸  = ∥ 𝑦′𝑖  − 𝑦𝑖 ∥2                                                    (2.1)
Таким образом, задачу обучения можно переформулировать в оптимизаци­ онную задачу минимизации функции ошибки на некоторой выборке 𝑄(𝑎 (𝑥),𝑍) → min.Решение задачи бинарной классификации – определение такого 𝑎 (𝑥), который минимизирует функцию потерь на заданном множестве (2.2).
 
𝑎 (𝑥) = min 𝑄(𝑎 (𝑥),𝑍)                              (2.2) Применительно к задаче выявления патологий объектами являются рент­ генограммы легких. Поскольку снимки являются черно-белыми изображениями, каждый пиксель изображения может быть представлен одним числом – значениям яркости в градациях серого. Этот показатель можно преобразовать к вещественно­ му путем нормализации. Таким образом, каждый рентгеновский снимок обучающей выборки может быть охарактеризован вектором, имеющим размерность r*r×1, где r*r – разрешение изображения. Последнее измерение отвечает за метку класса
объекта.
 
2.2.  Общие сведения о нейронных сетях
 
Искусственные нейронные сети представляют собой один из способов оп­ тимизации функции, в основе которого лежит построение сложных структур, имитирующих работу мозга человека.

2.2.1.  Математическая модель нейрона
 
Нервная система организма, являющаяся самым большим обработчиком информации, состоит из разных компонентов. Однако, каждая из составных частей строится из одинаково устроенных элементов, называемых нейронами. Каждый из таких элементов имеет ядро, способное накапливать электрический заряд. К ядру ведут многочисленные маленькие отростки, называемые дендритами. Они служат в качестве источника информации, поступающей от других узлов. От ядра также отходит большой отросток, аксон, служащий в качестве выхода для обработанной информации. Места соприкосновения дендритов одних нейронов и аксонов других называются синапсами. Они могут обладать разной силой, влияющей на степень и полноту передачи сигнала (если соединение сильное, то вся информация перейдет практически без потерь и наоборот). С течением времени и в силу различных причин сила места соединения может изменяться в большую или меньшую сторону. Именно с настройкой синапсов связана тренировка биологической нейронной сети, представленной нервной системой человека.
В 1943 году была представлена математическая модель нейрона ( рис.2.1),которая формальным языком описала устройство своего биологического аналога в организме человека Ядро нейрона представлено сумматором, осуществ­ ляющим «накапливание» поступающей по входам информации. Биологические
синапсы моделируются с помощью весов ω1,ω2,...,ω𝑑, умножаемых на входные
значения 𝑥1,𝑥2,..𝑥𝑑. Прежде чем отправить полученные сигналы на выход текущий нейрон осуществляет преобразование с помощью функции активации. Функция активации и веса – настраиваемые параметры, в зависимости от которых можно получить различные нейроны. Комбинация нейронов с нелинейной активационной функцией, называемая сетью, позволяет строить более сложные зависимости и увеличивать уровень абстракции.
2.2.2.  Функции активации
 
Функцию активации можно охарактеризовать как способ нормализации вы­ ходных данных. Она позволяет преобразовать данные в теле нейрона к значениям из определенного фиксированного диапазона. Основным требованием, предъяв­ ляемым к функциям активации, является ее нелинейность. Ниже представлены наиболее часто используемые активационные функции.

 

 
Рис.2.2. Математическая модель нейрона
 
Как отмечалось ранее, простейшей функцией активации является пороговая функция, которая равна единице, если аргумент превышает ноль, и равна нулю в противном случае. Однако такая функция не является удобной для использования, поскольку не является гладкой, то есть имеет разрыв в точке перехода – в нуле. Это является ключевым фактором при оптимизации нейронных сетей, о чем будет рассказано далее. Вместо этого используют ReLU (2.3) , что в переводе означает «выпрямленный линейный блок». Для такой функции легко определить производную (1 для положительных значений и 0 – для отрицательных). Помимо этого, она является биологически вдохновленной: как и в головном мозге при анализе информации активируется не все нейроны, а только часть, обрабатывающая фрагменты, которые представляют наибольший интерес. В частности, при обра­ ботке изображений «запускаются» нейроны с наиболее важными для конечного результата пикселями. Такое явление называется разреженностью активации.
 
𝑅𝑒𝐿𝑈 = max(𝑥,0)                                        (2.3)
Сигмоидная функция (sigmoid) (2.4) также функцией активации, которая используется в большом количестве архитектур нейронных сетей. Она непре­ рывно дифференцируема, всегда положительная и позволяет приводить значения всех аргументов к диапазону [0;1]. Назначением такой функции можно назвать фильтрация интенсивности входных значений.
1
𝑓 (𝑥) = 1 + exp−𝑥                                                                                     (2.4)

Альтернативной S-функцией, которая в отличие от сигмоиды отцентрирована в нуле и имеет более высокий размах, является гиперболический тангенс (tanh) (2.5).

𝑓 (𝑥) =

exp2𝑥 −1                                          (2.5)
exp2𝑥 +1

При решении задач многоклассовой классификации, когда количество ме­ ток в множестве Y больше двух в конце нейронной сети обычно размещают полносвязный слой, в котором количество нейронов равно количеству классов. Предполагается, что каждый из них ответственен за вероятность принадлежности к тому или иному классу. При этом вместо вычисления функции активации для каждого нейрона отдельно применяют специальную функцию софтмакс (англ. Softmax) (2.6), являющуюся обобщением логистической функции.
exp𝑦𝑖

.
 
𝑓 (𝑥) =


𝑚
 
𝑗 =1


exp


𝑦                                                                                                                                                                                                                                                     𝑗

(2.6)

Задача бинарной классификации является частным случаем описанной выше задачи при |𝑌 | = 2. При этом на последнем уровне используется всего одни нейрон, а функция софтмакс превращается в сигмоиду, характеризующую вероятность принадлежности к одному из двух классов. Тогда вероятность для другого класса легко вычисляется путем вычитания текущего значения из единицы.
 
2.2.3.  Оптимизация нейронных сетей
Как было отмечено выше, решение задачи классификации сводится к ми­ нимизации функции ошибки, в теории нейронных сетей называемой функцией потерь (англ. loss function),), на некоторой выборке. В большинстве случаев среди множества возможных способов используется метод гладкой оптимизации, пред­ ставленный градиентным спуском. Сам процесс обучения происходит следующим образом. На каждом из итерационных этапов нейронная сеть обладает неким вектором →−𝑤 , составленным из весов всех нейронов, составляющих данную ар­ хитектуру. В самом начале эти веса могут быть инициализированы случайными числами или нулями (вектор −𝑤→0). Далее вычисляется градиент функции потерь (2.7), показывающий направление наискорейшего возрастания функции.

 
     
 
 𝜕 𝑓   


 
 𝜕 𝑓
𝜕𝑤𝑛
 

 
∇ 𝑓 =

𝜕𝑤0
 ... 

(2.7)

 
Поскольку в ходе решения необходимо двигаться к минимуму, то на каждом следующем шаге вектор весов вычисляется с использованием антиградиента по формуле (2.8).
 
𝑤𝑡  = 𝑤𝑡−1 − α∇ 𝑓 (𝑤𝑡−1),                                             (2.8)
где α – градиентный шаг или «скорость обучения», подбираемый вручную гиперпараметр, определяющий скорость продвижения к минимуму функции. Сле­ дует отметить, что градиентный спуск показывает направление к минимуму, не всегда совпадающему с оптимальным.
Тем не менее, градиент показывает только частные производные функции потерь на выходе нейронной сети. Корректировка весов каждого нейрона проис­ ходит с помощью метода обратного распространения ошибки, в ходе которого используется правило нахождения производной сложной функции.
2.2.4.  Функции потерь
 
Как уже было отмечено, функция потерь позволяет определить качество классификации на обучающей выборке, определяя расхождения полученного результата от истинного. Поэтому к ней должен быть определен ряд требований, влияющий на выбор той или иной функции. Прежде всего, получаемые значения должны быть неотрицательными для получения однозначного представления о точности модели, а также результат должен приближаться к нулю при увеличении точности нейронной сети и отдаляться от нуля в противном случае. Помимо этого, использование метода гладкой оптимизации накладывает дополнительные ограничения:
1.    Функция потерь должна быть дифференцируема.
2.    Производная функции не должна быть равна нулю в достаточно боль­ шом множестве точек. В противном случае становится невозможным определить направление уменьшения функции.
Этим критериям удовлетворяет MSE (2.1), широко используемая при реше­ нии задач классификации. Однако при совместном ее использовании с сигмоидной

функцией активации на выходе модели возникает нежелательное явление, называ­ емое «параличом сигмоидной нейронной сети». Дело в том, что при вычислении производной функции потерь часто возможны случаи, когда получаемое значение равно нулю. Причиной этому служат множители σ(1 − σ), зависящие от аргумента сигмоиды на выходе сети. Поскольку на достаточно большой части области опре­ деления этой функции получаемые результаты стремятся к нулю или единице, то умножение на такие множители будет «обнулять» производную функции потерь с достаточно большой вероятностью.
По этой причине в задах классификации с использованием нейронных сетей используется ряд других функций. Широко применяемым вариантом является кросс-энтропия (англ. cross entropy, CE) (2.9), которая хорошо оценивает веро­ ятности и любые значения, лежащие в промежутке от нуля до единицы. Такие значения, как было отмечено, обеспечивает софтмакс.
𝐶𝐸 ( 𝑝,𝑡) = −
 
𝑡𝑐 log 𝑝𝑐,                                               (2.9)
 
∑︁𝑁





где 𝑡 -истинное значение класса, а 𝑝 – функция активации.
При решении задачи бинарной классификации (при N=2) образуется частный случай функции, называемый бинарной кросс-энтропией (BCE) (2.10), которая при использовании совместно с сигмоидной активационной функцией не име­ ет вышеупомянутых нежелательных явлений, а потому является оптимальным выбором.
 
𝐵𝐶𝐸 ( 𝑝,𝑡) = −𝑡 log 𝑝 − (1 − 𝑡) log (1 − 𝑝)                       (2.10)
2.2.5.  Сверточные нейронные сети
 
В настоящее время нейронные сети показывают наибольшую эффективность в решении задач распознавания изображений и видео. Высокие результаты дости­ гаются путем использования специальных архитектур, называемых свёрточными НС (СНС). Их особенностью является использование в своем составе двух до­ полнительных типов структур: слоев свертки (или конволюции) и пулинга (англ. pooling) (или подвыборки).
Появление сверточных нейронных сетей было вызвано рядом причин. Несмотря на то, что широкий круг задач способны решать и полносвязные НС, состоящие из большого количества идущих друг за другом слоев с нейронами

с различными функциями активации, настройка и практическое использование таких моделей даже на современных вычислительных устройствах не являет­ ся рациональным. Во-первых, для достижения желаемого результата требуется выборка больших размеров, учитывающая все возможные случаи расположения различных объектов на изображениях или видеофрагментах. Практический опыт показывает, что собрать качественный набор данных не всегда представляется возможным. Во-вторых, сами модели будут занимать существенное место в памяти, в которой должен храниться и использоваться в вычислениях большой вектор всех используемых параметров. Все это послужило причиной использования более эффективных для работы с неструктурированными данными СНС.
Прежде всего, операция свертки инвариантна относительно положения на изображении. СНС способны определять один и тот же объект, находящийся в разных углах рассматриваемой области. Это позволяет таким типам структур легче находить закономерности и легче обобщаться. Кроме того, при обучении учитывается взаимное расположение пикселей и дополнительная информация о структуре данных, что также помогает более качественно решать поставленную задачу. При этом решается проблема ограниченности ресурсов, поскольку зани­ маемое место в памяти и время для обучения существенно ниже по сравнению с классическими перцептронами. По этим причинам наиболее популярными в решении задач обработки изображений являются сверточные нейронные сети.
Рассмотрим структуру конволюционного слоя. Принцип действия такой архитектуры также был заимствован при изучении работы нейронов в мозге че­ ловека, в частности работы зрительной коры. При анализе изображения обычно происходит поэтапное сканирование участков рассматриваемого объекта в огра­ ниченном поле зрения, называемого перцептивным полем. При некотором проходе по всей площади изображения множество таких полей перекрываются, стимулируя в определенных моментах текущие нейроны, передающие полезную информацию об обнаруженных признаках в следующие обрабатывающие структуры. В НС свертка представляет собой некоторую матрицу чисел, называемую фильтром или ядром свертки. Размер этой матрицы определяет перцептивное поле (например, 5x5 пикселей или 3x3). Начиная с левого верхнего угла, происходит вычисление скалярного произведения между ядром и значениями текущей области изображе­ ния. На рисунке рис.2.3 представлен пример вычисления результата для элемента матрицы на пересечении 2-й строки и 2-ого столбца и свертки размером 3x3. Перемещая фильтр вдоль ширины и высоты входного представления происходит

свертка всего изображения, в результате которой образуется новая выходная матрица. Такая операция позволяет выделять характерные участки на изображении в соответствии с конфигурацией весовых коэффициентов ядер. Благодаря этому нейроны каждой группы активируются тогда, когда на изображении появляется фрагмент, подходящий под их фильтры.
 
 





 
 
Рис.2.3. Операция свертки
 
Как можно заметить, после проведения операции свертки размер выход­ ной матрицы оказывается меньше размера входного представления. При этом не учитываются значения пикселей, расположенных на границе изображения. Для устранения такого явления может применяться выравнивание – добавление пик­ селей вдоль всего периметра рассматриваемой матрицы. Обычно такие пиксели имеют нулевое значение. Количество добавляемых вокруг слоев – параметр, назы­ ваемый padding. На рисунке рис.2.4 изображен пример работы свертки для padding
= 1.
Еще одним настраиваемым параметром является шаг смещения перцеп­ тивного поля, имеющий название stride. В обычном случае при проходе поля значительно перекрываются за счет перемещения на один пиксель вправо и вниз соответственно. Как правило, шаги меньшего размера показывают лучший резуль­ тат, однако при необходимости возможно увеличить stride до 2 или в более редких случаях до 3 пикселей.
Следует отметить, что чаще всего на вход нейронной сети поступают изоб­ ражения в цветовой модели RGB, то есть в виде трехканального массива значений, отображающим количество красного, зеленого и синего цвета в каждом из пик­ селей. В таких случаях каждый из фильтров представляется в виде трехмерной

 
 
 

 
Рис.2.4. Операция свертки с padding
 
матрицы, имеющей в качестве третьего измерения – количество каналов входного представления (для RGB – значение 3). После проведения скалярного произведе­ ния значения в каждой из полученных матриц аналогичным образом складываются, образуя в результате одно из численных значений выходного канала. В конце построения результирующей матрицы, к каждому из ее элементов применяется функция активации, ассоциированная с текущим сверточным слоем. Чаще всего в таких структурах используется ReLU.
Таким образом, в общем случае сверточный слой имеет следующий ряд параметров:
–    padding (количество добавляемых нулевых пикселей по периметру матри­ цы);
–    шаг смещения (stride);
–    количество входных каналов;
–    количество выходных каналов (в одном слое мы можем использовать произвольное число фильтров).
Как правило, в ходе работы сверточного слоя происходит анализ входного представления с целью выявления ряда полезных признаков. За каждый из них отвечает одно из сверточных ядер. По этой причине в результате обработки количе­ ство хранимых матриц увеличивается, что приводит к нагрузке на вычислительный процесс. Для решения этой проблемы используются слои подвыборки, или пулинга. Сокращая пространственную размерность свернутых объектов, они также выпол­ няют функцию изменения масштаба, что позволяет выделять более общие признаки

на изображении, тем самым поддерживая процесс эффективного обучения модели. В процессе работы слоя пулинга также используется принцип перемещения окна фиксированного размера. Отличие заключается в способе вычисления результата: на выход может поступать среднее значение пикселей окна (average pooling), ми­ нимальное (min pooling) или максимальное (max pooling) значение. На рисунке рис.2.5 изображен пример последнего случая с окном размера 2x2 и шагом 2. Это позволяет уменьшить каждый глубинный слой в два раза, исключая тем самым 75% активаций. Многочисленные исследования эмпирическим путем подтверждают, что выделение максимального значения работает лучше среднего, поскольку при этом дополнительно происходит устранение дополнительных шумов. При поступ­ лении на вход многоканального изображения слой подвыборки работает с каждым каналом отдельно.
 





 
 
Рис.2.5. Операция подвыборки
 
В глубоких нейронных сетях обычно используется определенная последо­ вательность следующих друг за другом сверточных блоков, каждый из которых представлен конволюционным слоем и слоем пулинга. Если фильтры первых бло­ ков, расположенных у входа нейронной сети, позволяют обнаруживать границы, простейшие линии и градиенты, то верхние слои способны распознавать все более сложные геометрические фигуры и узоры. Количество блоков выбирается для каждого случая отдельно, причем с увеличением их числа возрастает не только способность показывать наилучшие результаты, но и количество параметров сети, а также увеличивается время обработки и обучения такой струкутры. В самом конце чередующиеся сверточные слои формируют вектор оконечных карт призна­ ков, который обычно передается на вход полносвязной части, осуществляющей классификацию на основе выделенных особенностей и признаков изображения. Типичный пример полной архитектуры СНС изображен на рисунке рис.2.6.

 
 

Рис.2.6. Устройство сверточной нейронной сети [7]
 
 
2.3.  Оценка качества классификации
 
Для качественной оценки алгоритмов бинарной классификации и сравнения их между собой необходимо введение ряда метрик. Простейшей из них является доля правильных ответов (англ. accuracy) (2.11), которая может использоваться в качестве первого показателя.
 

𝑎𝑐𝑐𝑢𝑟𝑎𝑐𝑦 =

𝑃 ,                                                      (2.11)
𝑁

где 𝑃 – количество правильно предсказанных элементов,𝑁 – общий размер выборки.
Тем не менее, нельзя строить модель, основываясь только на данной метрике, поскольку она не учитывает сбалансированность выборок (качество классификации для каждого из классов отдельно может быть значительно хуже общих показателей) и цены разных видов ошибок. Для введения дополнительных метрик обычно используется способ представления ошибок в задачах классификации, называемый матрицей неточностей (таб. 2.1).В строках матрицы отображаются истинные метки
классов 𝑦, а в столбцах – оценки классификатора 𝑎 (𝑥).
Таблица 2.1
Матрица неточностей
 
 
𝑎 (𝑥) = 1
𝑎 (𝑥) = 0
𝑦 = 1
True Positive (TP)
False Negative (FN)
𝑦 = 0
False Positive (FP)
True Negative (TN)
 
В задаче бинарной классификации матрица неточностей имеет две строки и два столбца. На их пересечении определяются как случаи правильной классифи­ кации (TP, TN), так и различные ошибки: ошибка I рода (ложное срабатывание,

FP) и ошибка II рода (ложный пропуск, FN). Обычно более интересующий класс получает метку 1. В задачах медицинской диагностики таким можно считать ситуацию «наличие патологии».
Метрика точность (precision) (2.12) является отношением верно распознан­ ных позитивных объектов к общему количеству позитивных вердиктов классифи­ катора. Она позволяет оценивать ошибку I рода.
 

𝑝𝑟 𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =

𝑇 𝑃
𝑇 𝑃 + 𝐹𝑃

(2.12)

Полнота (recall) (2.13) характеризует способность классификатора опреде­ лять как можно больше определять положительных ответов из ожидаемых. Она направлена на оценку ошибок II рода.
 

𝑟 𝑒𝑐𝑎𝑙𝑙 =

𝑇 𝑃
𝑇 𝑃 + 𝐹𝑁

(2.13)

В зависимости от типа решаемой задачи, основное внимание уделяется приросту одной из этих метрик. Очевидно, что при распознавании патологий на рентгеновских снимках гораздо важнее, чтобы модель пропускала как можно меньше патологических изображений пациентов, чем ошибочно относила здоровые снимки к группе больных, поскольку основной целью проведения исследований является своевременное выявление различного рода заболеваний на ранних стадиях. Это значит, что основным критерием оценки качестве должна являться полнота, которую необходимо максимизировать.
Практический опыт показывает, что одновременное достижение максимума обеих метрик не представляется возможным. Тем не менее, при выборе и сравнении моделей очевидным фактом является то, что наибольшие показатели полноты и точности говорят о наиболее высоком качестве классификации во всех случаях. Для удобства используется F-мера (2.14), позволяющая объединить эти две метрики и являющаяся их средним гармоническим. Она, в отличие от доли правильных ответов, учитывает распределение по классам, что является ее преимуществом.

𝐹 = 2 · 𝑝𝑟 𝑒𝑐𝑖𝑠𝑖𝑜𝑛 · 𝑟 𝑒𝑐𝑎𝑙𝑙
𝑝𝑟 𝑒𝑐𝑖𝑠𝑖𝑜𝑛 + 𝑟 𝑒𝑐𝑎𝑙𝑙


(2.14)

Таким образом, основными оценками качества в работе являются доля правильных ответов (в качестве начального показателя), полнота и F-мера.

2.4.  Выводы
 
Нейронные сети – технология, которая пользуется исключительной популяр­ ностью в настоящее время в силу возможности показывать наилучшие результаты в широком спектре проблем, в особенности касающихся анализа и обработки изображений и других видов неструктурированных данных. Однако, высокие показатели эффективности – следствие достаточно сложных структур и алгорит­ мических методов преобразования, требующих детального понимания. В данной главе произведено как описание общих положений устройства нейронных сетей, так и осуществлен разбор сверточных блоков, предназначенных для обработки изображений. В конце главы отображены выбранные метрики качества классифи­ кации, на основе которых будет производиться выбор модели для интеграции в веб-приложение.
 
 
ГЛАВА 3. ПРОГРАММНАЯ РЕАЛИЗАЦИЯ
 
В данной главе описывается основные этапы реализации веб-приложения и классификационной модели. В параграфе 3.1 определяются основные программные средства, использованные при разработке. Параграф 3.2 посвящен построению классификационной модели: выбору данных для обучения, их обработке, а также выбору подходящих типов нейронных сетей. В параграфе 3.3 указана основная функциональность разрабатываемого веб-приложения, способ взаимодействия с пользователем и моделью, используемая архитектура.
 
3.1.  Определение программных средств
 
После формализации решаемой задачи необходимым действием является определение наиболее подходящих программных средств, включающих языки программирования, библиотеки, фреймворки. От правильности их выбора зависит то, насколько эффективным и полным окажется разработанное решение. Посколь­ ку разработка классификационной модели и веб-приложения, использующего ее, являются различными по характеру задачами, то для каждой из них выбор программных средств происходил отдельно.

3.1.1.  Выбор средств разработки классификатора
 
Следует отметить, что решить задачу классификации изображений с при­ менением машинного обучения возможно практически на любом языке програм­ мирования, поскольку в каждом из них на текущий момент имеются реализации библиотек и модулей для построения и обучения нейронных сетей. Тем не менее, каждый из языков в общем случае предназначен для решения узкого круга задач. По этой причине рассматривались средства, наиболее используемые в таких сферах, как обработка данных и МО.
C++ – имеющий высокую производительность компилируемый язык програм­ мирования, одновременно обладающий высокоуровневыми и низкоуровневыми возможностями. Высокая популярность обусловлена его высокой скоростью, что является одним из важных критериев при интеграции моделей машинного обуче­ ния в программное обеспечение. Одним из минусов языка является сложность в освоении и необходимость в написании большого объема кода в силу особенностей синтаксиса, что может приводить к непреднамеренным ошибкам и трудностям в использовании.
Язык R – язык программирования с открытым исходным кодом для стати­ стических вычислений и визуализации графики, широко используемый в анализе данных. Как правило, этот язык является целевым для решения общих задач МО, таких как регрессия, классификация и формирование деревьев решений. Несмотря на относительную простоту интеграции с другими инструментами, R обладает рядом особенностей, которые усложняют его изучение. К ним, например, можно отнести нетрадиционные структуры данных и индексирование.
Python – широко применяемый интерпретируемый высокоуровневый язык программирования, лидирующий в сфере машинного обучения, поскольку имеет простой и гибкий синтаксис, мощные средства визуализации данных, является кроссплатформенным, позволяет легко реализовывать различные алгоритмы и на данный момент имеет большое количество реализованных решений. Именно этот язык использовался в данной работе для построения модели.
На следующем этапе было необходимо выбрать основную библиотеку для построения и обучения глубоких нейронных сетей. Наиболее применяемыми и эффективными являются два реализованных решения: библиотека TensorFlow от Google [16] и фреймворк PyTorch от инженеров Facebook [15]. Обе технологии имеют открытый исходный код и разработаны для решения широкого круга задач

машинного обучения и искусственного интеллекта с использованием НС. В основе их работы лежит работа с тензорами – многомерными численными массивами, которыми представляются любые рассматриваемые модели. Помимо этого, они поддерживают распараллеливание вычислений на графическом процессоре (GPU), что позволяет увеличивать производительность и уменьшать время обучения. Следует отметить, что невозможно однозначно выделить наилучшее средство для решения поставленной задачи – оба варианта имеют свои достоинства и недостатки. TensorFlow, в частности, имеет работающий поверх высокоуровневый API – Keras, который имеет низкий порог вхождения и позволяет быстро разработать модель начинающему программисту. Тем не менее, в данной работе использовался PyTorch, особенностями которого являются использование объектно-ориентированного подхода для работы с необходимыми модулями и возможность точной настройки сети на более «низком уровне». Последнее положение также подтверждает факт, что большинство исследовательских задач в области глубокого обучения реализуется с использованием PyTorch.
Для уменьшения времени обучения классификатора использовался Google
Colab – интерактивная облачная среда, построенная на основе блокнота Jupiter. Ее главной особенностью является возможность аренды мощных графических процессоров, которые обрабатывают данные с большей скоростью за счет распа­ раллеливания нагрузки. Финальный скрипт для использования веб-приложением был разработан в среде программирования PyCharm, разработанной компанией JetBrains.
 
3.1.2.  Выбор средств разработки веб-приложения
 
Любое веб-приложение в общем случае имеет клиент-серверную архитектуру, в которой пользователь (клиент), используя браузер, осуществляет взаимодействие с сервером приложения. Во многих случаях для написания этих серверной части используются различные языки программирования. Тем не менее, в данной работе веб-приложение полностью было разработано с использованием JavaScript (JS) – интерпретируемого мультипарадигменного языка программирования. В клиент­ ской части он отвечает за интерактивность веб-страницы. Ее структура оформлена с помощью разметки HTML, за внешний вид отвечают таблицы стилей CSS, а взаимодействие с пользователем достигается с помощью JS (динамическое изме­ нения элементов, вывод загружаемых данных и т. д.). Для уменьшения количества

кода, упрощения манипулирования динамическими элементами страницы (DOM), а также для более удобного написания асинхронных запросов дополнительно использовалась библиотека JQuery.
Использование JavaScript в качестве внутреннего инструмента програм­ мирования для разработки серверной части достигается с помощью Node.js – специальной среды выполнения, позволяющей запускать JS-приложения вне среды браузера. Ее особенностями являются достаточно высокая производительность и легковесность. Благодаря этому данная технология широко используется в раз­ работке различных типов веб-приложений, в том числе и высоко нагруженных. Структурно Node.js состоит из так называемых «пакетов», а также может под­ ключать и использовать другие внешние библиотеки, написанные на различных языках. Используемые в работе пакеты описаны в разделе 3.3.
 
3.2.  Разработка классификатора
 
3.2.1.  Выбор и подготовка данных для обучения
 
Для создания классификатора, способного осуществлять классификацию снимков легких, решающую роль играет правильно подобранный набор данных для обучения. Поскольку в работе было решено использовать нейронные сети, которые имеют потребность в обучении на тысячах и десятках тысяч примеров, то основным критерием выбора выступал общий размер используемого датасета. Дополнительно также учитывалось разнообразие представляемых видов патологий. После тщательного анализа имеющихся в открытом доступе наборов рент­ генограмм легких были выбраны два набора, которые имеют наибольший размер. Первый из них, NIH Chest x-ray dataset [13], подготовленный Клиническим Цен­ тром Национального Института Здравоохранения США, представлял наибольший интерес, поскольку имел около 112 тыс. снимков с 14 различными видами забо­ леваний и заявленной точностью нанесения меток диагнозов около 90%. Однако, при детальном исследовании набора выяснилось, что немалая часть изображений имеет ряд дефектов, в числе которых сильная зашумленность (размытие или засвет), наличие посторонних предметов и неверное положение грудной клетки, что делает ее непригодной для обучения. Кроме того, сомнение вызвало и качество разметки – некоторые рентгенограммы при заявленных заболеваниях ничем не

отличались от здоровых. При большом объеме набора выбор подходящих примеров, осуществляемый вручную, мог занять достаточно большое время.
По этой причине было решено использовать второй датасет, COVID-19 Radiography Database    [9], который имеет меньшее количество «дефектных» изображений. Несмотря на свое название, набор располагает снимками с тремя различными видами инфекционных заболеваний легких (коронавирусная инфекция, вирусная пневмония и затемнение легких), которые, как известно, являются наиболее распространенными среди патологий грудной клетки. Это позволяет сделать предположение о том, что хорошо обученная модель на таких примерах сможет с достаточной точность обобщить основные закономерности и определять наличие заболевания на новых снимках вне зависимости от конкретного диагноза. Среди достоинств данного набора можно выделить тот факт, что его авторы осуществляли ручной сбор рентгенограмм из таких источников, как медицинские школы, международные радиологические сообщества и Интернет (все источники для каждого типа болезни указаны в пояснительном тексте). Полная версия содержит около 34 тысяч изображений, причем данные регулярно обновляются, и последнее на момент обращения пополнение зарегистрировано в марте 2022 года.
В итоге, для обучения классификатора использовалась выборка, состоящая
из 21165 снимков: 10192 здоровых, 3616 с коронавирусной инфекцией, 1345 с вирусной пневмонией и 6012 с затемнением легких, вызванных другими ин­ фекциями. Все изображения с заболеваниями были объедены в единый класс
«патология», размер которого приблизительно равен общему количеству здоровых рентгенограмм.
 
3.2.2.  Предварительная обработка данных
 
Для увеличения количества примеров и уменьшения шанса возникновения явления переобучения в процессе предварительной обработки изображений при­ менялись способы искусственного расширения обучающей выборки – аугментации. Перед передачей снимка ко входу нейронной сети к нему применялись следующие преобразования:
1.    Сжатие до размера 299x299 пикселей. Данная процедура проводилась с использованием готового программного метода библиотеки, который выполняет изменение разрешения с помощью субдискретизации и били­ нейной интерполяции.

2.    Обрезка изображения по центру до размера 280x280. Поскольку очевидно, что границы снимка рентгена легких не несут полезную информацию, то их удаление приведет к увеличению вероятности построения более точной модели.
3.    Финальное сжатие до разрешения 224x224 пикселя.
4.    Эквализация гистограммы яркости пикселей. Данная процедура позволяет усилить локальный контраст изображений, что также ведет к улучшению выявления патологий.
5.    Отражение изображения по горизонтали с вероятностью 0.5.
6.    Случайный поворот на значение угла до 15 градусов в каждую сторону.
7.    Представление изображения в виде тензора для дальнейшей обработки сетью.
8.    Нормализация данных. После преобразования в тензор из каждого его элемента вычитается среднее значение и осуществляется деление на стандартное отклонение. В результате такой процедуры данные ограни­ чиваются конкретным диапазоном значений для упрощения обучения.
Все перечисленные методы позволяют на каждом проходе по обучающему набору (эпохе) передавать видоизмененную рентгенограмму, которая будет оце­ ниваться нейронной сетью как совершенно другое изображение. Это позволяет увеличить выборку, а также улучшить обучение модели и избежать «запоминания» ею всего набора без выделения нужных закономерностей.
3.2.3.  Обучение классификатора
 
В ходе разработки модели был использован подход, называющийся пе­ редача обучения (англ. transfer learning) (рис.3.1). Основной принцип данного метода заключается в том, что в теле сети используется заранее предобученная структура с фиксированными значениями весов. В соответствии со спецификой задачи модифицируются только последние слои, называемые также головой НС. В PyTorch имеется ряд подготовленных моделей, которые использовались для решения популярной задачи ImageNet 1000. В этом соревновании, которое регу­ лярно проводилось до 2017 года, необходимо было показать наилучшую точность в разбиении более 15 миллионов изображений на 1000 классов. Особенностью примеров из этой базы является то, что все они использовались с расширением 224x224 пикселя. Именно по этой причине все рентгенограммы легких сжимались

до этого размера. Безусловно, с ухудшением качества снимков мы теряем часть ин­ формации, которая потенциально может содержать признаки различных патологий. Тем не менее, используемый набор данных хранит изображения с расширением 299x299, что также является достаточно невысоким разрешением.
 





 
Рис.3.1. Принцип работы метода transfer learning
 
Для построения использовались две модели, основанные на различных типах архитектур: ResNet и DenseNet. В обеих сетях были выбраны одинаковые параметры головной части: последний полносвязный слой завершался двумя нейронами, отображающими численные значения по принадлежности к каждому из возможных классов; в качестве функции потерь была выбрана кросс-энтропия, а в качестве функции активации использовались ReLU и софтмакс на последнем слое.
Первая модель, ResNet, была предложена специалистами Microsoft в 2015 году для решения задачи ImageNet 1000. Основой ее структуры стало использование так называемых остаточных (англ. residual) блоков (рис.3.2), из-за которых сеть и получила свое название.
Любая из глубоких сетей, имеющая большое количество слоев, подвержена нежелательному явлению, которое имеет название «затухание градиента». Как было отмечено, при обучении НС используют методы гладкой оптимизации, ко­ торые, вычисляя антиградиент функции потерь, последовательно перемещаются по его направлению в точку минимума, корректируя веса модели. Такой способ

 

Рис.3.2. Устройство остаточного блока
также называется методом обратного распространения ошибки. Однако, при такой последовательной корректировке веса, находящиеся ближе к входу, способны изменяться в гораздо меньших пределах, так как до них градиент доходит, «за­ тухая» при проходе по сети. Для устранения такого явления и был разработан остаточный блок. Имея в своем составе ответвление со значением из входа в текущий блок (“skip connection”), такая структура на выходе поэлементно сум­ мирует полученное после обработки внутри значение функции с аргументом из ответвления (𝐹 (𝑥) + 𝑥 ), благодаря чему производная функции потерь в немного измененном виде способна протекать в предыдущую часть сети. Если модель будет последовательно состоять из остаточных блоков, это обеспечит распространение производной функции потерь на выходе из НС до самых первых слоев. На данный момент существует несколько модификаций ResNet, отличающихся количеством таких блоков (ResNet18, ResNet34, ResNet50 и т. д.). В данной работе использова­ лась модели ResNet18 и ResNet34. Структура наименьшей из них изображена на рис.3.3. В этих блоках кроме свертки и субдискретизации также располагаются слои батч-нормализации.

 

 
Рис.3.3. Архитектура сети ResNet 18 [7]
 
Вторая модель, DenseNet, является модернизацией остаточной нейронной сети. Если в предыдущем случае ответвления переносили информацию только в следующий блок, то в плотной сети (от англ. dense) (рис.3.4) каждый следующий блок получает дополнительные входные данные от всех предыдущих и передает свои собственные карты признаков всем последующим слоям. При этом использу­ ется поэлементная конкатенация признаков. Таким образом, каждый новый блок получает «коллективные знания» от всех предшественников.
 





 
Рис.3.4. Архитектура сети DenseNet [15]
 
Использование такого подхода позволяет уменьшить количество выходных каналов при свертке без потери точности, делая сеть более компактной и тонкой. Дополнительно возможно введение коэффициента 𝑘, отображающего дополни­ тельное количество каналов для каждого нового слоя. Каждый из плотных блоков состоит из трех слоев: батч-нормализации, слоя актвации ReLU и свертки областью 1x1 для изменения количества каналов.

Как и первый тип модели DenseNet частично устраняет проблему затухания градиента за счет использования дополнительных ответвлений для каждого из блоков. Большая компактность и меньшее количество параметров соответственно приводит к увеличению вычислительной эффективности сети. Кроме того, за счет передачи признаков от первых блоков до последних такая сеть осуществляет классификацию, оперируя функциями всех уровней сложности, а значит может с большей долей вероятности учитывать более гладкие границы решения. В работе также использовалась самый простой подтип сети со 121 слоями.
Имеющийся датасет был разделен на две части: тестовую (80% от общего количества) выборку, на которой происходило обучение, и валидационную вы­ борку (остальные 20%) для проверки показателей эффективности. На начальном этапе для определения общей способности выявить закономерность данных была задействована ResNet18. Обучение длилось в течение 20 эпох, результаты кото­ рого изображены на графике (рис.3.5), отображающем зависимость количества правильных ответов сети и функции потерь на обеих выборках от количества эпох. Это позволяет сделать вывод о том, что обучение только последнего классифи­ кационного полносвязного слоя с сохранением предобученных значений весов на сверточных блоках не приводит к увеличению эффективности распознавания, поскольку каждый из графиков практически не изменяет своего значения с тече­ нием эпох (количество правильных ответов составляет 84%, а значение функции потерь – 0.3). Первостепенной причиной такого результата является специфич­ ность используемых данных. Предобученные модели учились классифицировать разнородные объекты: породы собак, рукописные элементы и т. д. Распознавание патологий на снимках грудной клетки – совершенно другая задача, в ходе которой необходимо определять малозаметные помутнения в структуре легочных полей на изображении, представленном практически в черно-белой гамме с невысоким контрастом.
Для улучшения значения метрик был использован подход, называемый
тонкой настройкой нейронной сети. Его отличием от передачи обучения является то, что дополнительно происходит «разморозка» всех параметров НС, в результате которой с каждый оптимизационным шагом мы изменяем все веса модели методом обратного распространения ошибки. Благодаря этому сеть может перестроиться под текущую задачу и показывать более точный результат.
Для каждой из трёх архитектур (ResNet18, ResNet34, DenseNet121) в хо­ де обучения подбирались различные методы оптимизации, значения скорости

 

 
Рис.3.5. Результаты обучения ResNet18 при transfer learning
 
обучения. Для общей оценки результатов был построен сравнительный график, отображающий показатели количества правильных ответов и значений функции по­ терь на валидационной выборке для трех моделей с наилучшими гиперпараметрами (рис.3.6).





Рис.3.6. Результаты обучения при точной настройке
 
Согласно полученным данным все типы моделей показывают приблизи­ тельно равные значения функции потерь, accuracy (чуть более 94%) и остальных метрик. Это может говорить о том, что использованных архитектур сверточных нейронных сетей достаточно для обобщения рассматриваемой зависимости в данных, а дальнейшее повышение точности может быть ограничено неправильно установленными метками классов для части набора. По этой причине в ходе

проведения сравнительного анализа моделей рассматривались дополнительные критерии, имеющие значения в рамках использования готовой сети в программном обеспечении. Первым из них является среднее время инференса модели, то есть время предсказания обученной сетью на новых подаваемых данных. Для увеличе­ ния точности осуществлялось 10 замеров не на одном изображении, а на наборе (батче) из 4 снимков. Вторым критерием является размер файла сериализованной модели с расширением pt, в котором непосредственно хранятся слои и значения весов сети. Результаты измерения метрик отображены в таблице 3.1.
Таблица 3.1
Показатели эффективности меделей на валидационной выборке
 
 
Accuracy
Precision
Recall
F1
t инференса,мс
Размер,Мб
𝑅𝑒𝑠𝑁𝑒𝑡18
0.941
0.94
0.94
0.94
21,4
44
𝑅𝑒𝑠𝑁𝑒𝑡34
0.945
0.96
0.93
0.95
37,4
83
𝐷𝑒𝑛𝑠𝑒𝑁𝑒𝑡121
0.946
0.96
0.94
0.95
98,8
31
 
Анализ таблицы позволяет сделать вывод о том, что оптимальной моделью является ResNet18. Тем не менее, наилучшую сеть для использования серверной частью веб-приложения возможно определить после проведения тестирования на специально подготовленной выборке изображений, с которыми ни одна из рассматриваемых моделей не взаимодействовала.
 
3.3.  Разработка веб-приложения
 
После разработки алгоритма ИНС, решающей проблему бинарной клас­ сификации легких, необходимо разработать прикладное приложение, которое является средством коммуникации пользователя с полученной моделью. Посколь­ ку основная задача приложения состоит в осуществлении первичной сортировки поступаемого набора рентгенограмм на здоровые и с признаками патологии, было принято решение об интегрировании обученной нейронной сети в веб-приложение. Полученное программное обеспечение (ПО) имеет классическую клиент-сервер­ ную архитектуру.
Веб-приложение имеет следующую схему работы. Пользователь с помощью клиентской части осуществляет загрузку одной или серии рентгенограмм в брау­ зере. После нажатия на кнопку данные отправляются на сервер, где помещаются в рабочую директорию для дальнейшей обработки. На следующем этапе проис­ ходит вызов серверной частью скрипта, который загружает сериализованную в

файле готовую модель и подает ей на вход переданные изображения. Результаты обработки возвращаются клиенту, где в дальнейшем происходит их отображение пользователю. Описанная выше схема изображена на рис.3.7.
 





 
Рис.3.7. Общая структура работы веб-приложения
 
Поскольку разрабатываемое решение имеет определенный функционал, нацеленный на выполнение одной задачи, было принято решение о создании одностраничного динамически изменяющегося веб-приложения. Клиентская часть представляет собой единственный HTML-файл, на котором расположена формы для загрузки одного или нескольких изображений. Кроме этого, при изменении состояния формы загрузки файлов в правой части также изменяется область предварительного просмотра, в которой отображены сжатые изображения, их названия и размер. Изменения структуры страницы обеспечивается за счет ис­ пользования библиотеки JQuery для описания функций-обработчиков событий. Такими событиями являются:
–    загрузка пользователем файлов в форму;
–    вывод результатов распознавания патологий на изображениях и самих снимков.
Отправка данных на сервер осуществляется посредством AJAX-запросов, передающих изображения в качестве переменной типа FormData. При этом, преду­ смотрена возможность загрузки архива с несколькими цифровыми снимками. Графический интерфейс приложения представлен на рис.3.8.
Как отмечалось выше, серверная часть приложения реализована с помощью среды выполнения Node.js. В данной работе использовался ряд вспомогательных Node пакетов.
Главным из них является фреймворк Express, позволяющий развертывать серверную часть веб-приложения и обеспечивать интерфейс для взаимодействия с ней. Поскольку приложение подразумевает небольшое количество взаимодействий с сервером, был разработан API архитектуры REST, который использует унифици­

 

Рис.3.8. Графический интерфейс приложения
 
рованные указатели ресурсов URL для доступа к определенным данным сервера. Основные точки входа отображены таблице 3.2.
Таблица 3.2
Программный интерфейс приложения
 
Метод
Путь
Действие
𝐺𝐸𝑇
/
Получить основную страницу - index.html с файлами css, js
𝑃𝑂𝑆𝑇
/predictImages
Определить наличие патологий для ряда отправленных изображений
𝑃𝑂𝑆𝑇
/predictArchive
Определить наличие патологий для архива с изображениями
𝐺𝐸𝑇
/:file_name
Получить запрашиваемое изображение
 
Кроме этого, использовались другие вспомогательные пакеты:
–    Multer - работающий поверх express пакет, предназначенный для работы с файлами и позволяющий обрабатывать их на серверной части. С его помощью осуществляется проверка файла на соответствующий тип и допустимый размер.
–    Fs - библиотека для работы с файловой системой сервера, поиска нужных файлов для классификации.
–    Python-shell - библиотека для запуска скриптов, написанных на языке Python. C его помощью осуществляется вызов сервером необходимо­ го модуля для загрузки модели из файла, предварительной обработки изображений и осуществления классификации.

3.4.  Выводы
 
В ходе работы был проведен анализ доступных наборов цифрового рентгена легких для обучения и выбран наиболее подходящий. Кроме этого, были опреде­ лены основные способы предварительной обработки снимков, а также обучены три типа архитектур сверточных нейронных сетей, проведена их сравнительная ха­ рактеристика на основе рассматриваемых метрик. Для взаимодействия с моделью было разработано одностраничное веб-приложение, описана его функциональность, интерфейс взаимодействия и принцип работы.
 
 
ГЛАВА 4. ТЕСТИРОВАНИЕ И АНАЛИЗ ПОЛУЧЕННЫХ РЕЗУЛЬТАТОВ
 
Данная глава посвящена описанию и анализу результатов тестирования разработанного программного обеспечения. Производилась проверка правильности функционирования как классификационной модели на предмет правильности определения классов снимков, так и веб-приложения с точки зрения пользователя.
 
4.1.  Тестирование моделей
 
После достижения приемлемых результатов трех различных моделей на выбранном наборе данных необходимо удостовериться в том, что обученные классификаторы правильно выявили основные зависимости и не переобучились под используемый датасет. Для этой цели была составлена тестовая выборка из 35 рентгенограмм легких (16 здоровых и 19 патологических). Сбор изображений осу­ ществлялся из 8 различных открытых наборов, в результате чего для тестирования были подобраны здоровые снимки и снимки с различными патологиями, имеющие различное расширение (jpeg, png) и разрешение (от 299x299 до 2494x2048 пиксе­ лей). Кроме того, качество нанесения меток диагнозов для каждого снимка было проверено опытным врачом-рентгенологом.
В результате тестирования все модели показали одинаковый результат: precision – 0.82, recall – 0.95, F-мера – 0.88. Матрица ошибок классификации изображена на рис.4.1.
Следует отметить, что классификатор ошибается в изображениях, пред­ ставленных в низком качестве до преобразований. Малое разрешение затрудняет

 

 
Рис.4.1. Матрица ошибок для тестовой выборки
 
постановку диагноза даже квалифицированным специалистам. Поэтому, если обеспечить поступление на вход снимки достаточно высокого разрешения, что позволяют имеющиеся в большинстве медицинских учреждений рентгенологиче­ ские аппараты, это приведет к большей точности распознавания.
 
4.2.  Тестирование веб-приложения
 
После разработки веб-приложения было проведено тестирование его функ­ ционирования, в ходе которого был выявлен ряд случаев, при которых недобро­ совестный пользователь мог вызвать сбои в работе программного обеспечения. Для устранения таких ситуаций были реализованы дополнительные обработчики, включающие:
–    проверку на расширение файла (была предусмотрена возможность загрузки только изображений – jpg, jpeg, png, и архивированных файлов в формате zip);
–    проверку на размер загружаемого файла (изображения, не превышающие 3 Мб, и архивы до 50 Мб).
В случае несоблюдения пользователем указанных требований при попытки отправить файлы на сервер ему отображается предупреждение с текстом ошибки. Дополнительно в секции с предварительным просмотром загружаемых файлов красным цветом выделяются файлы, имеющие недопустимый тип расширения рис.4.2.

 

Рис.4.2. Пример реакции системы на действия пользователя
 
4.3.  Выводы
 
В результате тестирования основных компонентов разработанного про­ граммного обеспечения было установлено, что они обеспечивают заявленную функциональность. При корректной работе с интерфейсом пользователя харак­ терных сбоев и неполадок выявлено не было.
Тем не менее, существует большой ряд улучшений реализованного прототипа как с точки зрения веб-приложения, так и самой классификационной модели. Прежде всего, нейронные сети отличает слабая интерпретируемость данных, что в какой-то степени позволяет определять глубокие модели как некоторые «черные ящики», осуществляющие сложные и неотличимые преобразования. В связи с этим допустимым решением является добавление элементов объяснительного интеллекта. Например, это может быть достигнуто совместным использованием моделей для определения словесного описания диагноза или выделения цветом подозрительной области на изображении. Что касается разработки веб-приложения, то решением может являться добавление базы данных пользователей и возможности их регистрации для сохранения истории загрузок изображений.

ЗАКЛЮЧЕНИЕ
 
Рентгенологическое исследование грудной клетки является важным методом визуализации для диагностики респираторных заболеваний. В ходе исследова­ тельской части данной работы были рассмотрены основные методы цифровой обработки изображений органов грудной клетки, которые применялись и продолжа­ ют применяться для увеличения возможности правильной интерпретации снимков. Также произведен анализ основных методов классификации рентгенограмм, в результате которого были выделены нейросетевые структуры, в частности свер­ точные нейронные сети, как наиболее эффективный способ в рамках применения в системах вспомогательной диагностики. Дополнительно было подробно изучено их строение и рассмотрен ряд метрик для оценки эффективности обучения.
В рамках практической части работы был подобран набор снимков циф­ рового рентгена, на котором производилось обучение нескольких архитектур глубоких нейронных сетей. В рамках тестирования созданных структур была произведена оценка эффективности распознавания патологий на тестовом наборе рентгенограмм, подтвержденном квалифицированным врачом-рентгенологом. Для демонстрации функциональности и взаимодействия с потенциальными пользова­ телями обученная модель была интегрирована в разработанное веб-приложение, которое позволяет производить первичную фильтрацию набора загружаемых изоб­ ражений рентгена легких на предмет наличия патологии.

СПИСОК СОКРАЩЕНИЙ И УСЛОВНЫХ ОБОЗНАЧЕНИЙ
 
API   Application Programming Interface
CSS   Cascading Style Sheets DOM           Document Object Model GPU   Graphics Processing Unit
HTML   HyperText Markup Language REST          Re presentational S tate T ransfer URL Uniform Resource Locator
ВКР   Выпускная квалификационная работа.
МРТ   Магнитно-резонансная томография

СЛОВАРЬ ТЕРМИНОВ
 
Артефакты — искусственные погрешности в процессе рентгенологического исследования, значительно ухудшающие качество изображения.
Билинейная интерполяция — обобщение линейной интерполяции одной переменной для функций двух переменных.
Окклюзия — нарушение проходимости полых анатомических образований за счёт поражения их стенок.
Скрининг — определенный набор диагностических процедур и консультаций специалистов, направленный на выявление заболеваний у клинически бессимп­ томных или имеющих минимальные клинические проявления лиц.
Эквализация — процедура выравнивания гистограммы изображения, путем воздействия (т.е. коррекции) яркости отдельных пикселей.

СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ
 
1.       Абдулракеб А., Сушкова Л. Обзор методов сегментации опухолей на МРТ-изображениях головного мозга // Прикаспийский журнал: управление и высокие технологии. — 2015. — № 1. — С. 122—138. — URL: https://elibrary.ru/ item.asp?id=23592407 (дата обращения: 13.12.2021).
2.       Ефремов А. Поиск аномалий в рентгеновских снимках при помощи глубо­ кого машинного обучения с использованием предварительной обработки снимков для сегментации легких и удаления костей / Санкт-Петербургский государственный университет. — 2018.
3.       Кравченко Д. Рентген легких. Рентгенологические синдромы при заболе­ ваниях легких. — 2018. — URL: https://www.tiensmed.ru/news/rentgenlegkih2.html (дата обращения: 10.04.2022).
4.       Тимофеева Л., Быкова А., Алешина Т. Основные рентгенологические синдромы патологии легочной ткани. — Чебоксары: Издательство Чувашского университета, 2013.
5.       Хаджибаев А., Адылова Ф. Роль искусственного интеллекта в прогнозиро­ вании проблем covid-19: аналитический обзор // Вестник экстренной медицины. — 2020. — URL: https://cyberleninka.ru/article/n/rol-iskusstvennogo-intellekta-v- prognozirovanii-problem-covid-19-analiticheskiy-obzor (дата обращения: 15.04.2022).
6.       Boykov Y., Jolly M.-P. Interactive graph cuts for optimal boundary amp; region segmentation of objects in N-D images // Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001. Т. 1. — 2001. — 105—112 vol.1. — DOI 10.1109/ICCV.2001.937505.
7.       Transfer Learning with Deep Convolutional Neural Network (CNN) for Pneumonia Detection Using Chest X-ray / T. Rahman [и др.] // Applied Sciences. — 2020. — Т. 10, № 9. — DOI 10.3390/app10093233. — URL: https://www.mdpi.com/ 2076-3417/10/9/3233.
8.       Van Ginneken B., Ter Haar Romeny B., Viergever M. Computer-aided diagnosis in chest radiography: a survey // IEEE Transactions on Medical Imaging. — 2001. — Т. 20, № 12. — С. 1228—1241. — DOI 10.1109/42.974918.
9.       COVID-19 Radiography Database. — URL: https://www.kaggle.com/datasets/ tawsifurrahman/covid19-radiography-database (visited on 16.05.2022).

10.       Islam M. Abnormality Detection and Localization in Chest X-Rays using Deep Convolutional Neural Networks. — 2011. — URL: https://arxiv.org/pdf/1705.09850.pdf (visited on 10.04.2022).
11.       Le K.-T. Gravity Segmentation of Human Lungs from X-ray Images for Sickness Classification // InTech-03 / под ред. C. Kasemet. — Thailand: Chiang Mai University, 2003. — С. 428—433. — (InTech-03 ; Conference date: 01-01-2003).
12.       Manju Bhargavi P., Sai Kiran Mayee V. A comparison of image segmentation techniques, otsu and watershed for x-ray images // International Journal of Research in Engineering and Technology. —. — URL: https://www.academia.edu/21435286/ A_COMPARISON_OF_IMAGE_SEGMENTATION_TECHNIQUES_OTSU_AND_ WATERSHED_FOR_X_RAY_IMAGES?email_work_card=view-paper (visited on 15.04.2022).
13.       NIH Chest X-rays. — URL: https://www.kaggle.com/datasets/nih-chest- xrays/data (visited on 16.05.2022).
14.       Otsu N. A Threshold Selection Method from Gray-Level Histograms // IEEE Transactions on Systems, Man, and Cybernetics. — 1979. — Vol. 9, no. 1. — P. 62–66.
15.       PyTorch documentation. — URL: https://pytorch.org/hub/pytorch_vision_ densenet (visited on 16.05.2022).
16.       TensorFlow documentation. — URL: https://www.tensorflow.org/api_docs (visited on 16.05.2022).
17.       Tharani R., Krishnamurthy M. Segmentation of chest radiographs infected by tuberculosis using graph-cut // Global Journal of Engineering Science and Re- searches. —. — (Visited on 15.04.2022).
18.       WHO Director-General’s opening remarks at the media briefing on COVID-19. — 2020. — URL: https://www.who.int/director-general/speeches/detail/ who-director-general-s-opening-remarks-at-the-media-briefing-on-covid-19---11- march-2020 (visited on 10.04.2022).

Приложение 1 Создание и настройка классификационной модели
 
 
 
import numpy as np import random
from random import shuffle
5 import os
from tqdm import tqdm import shutil
import matplotlib . pyplot as plt import cv2
10 import time import copy
 
import  torch import torchvision
15 from torchvision import datasets , models , transforms
 
from sklearn import metrics
from sklearn . metrics import classification_report , Confusion Matrix Display
 
20
def init_random_seed ( value =42) : random . seed ( value )
np. random . seed ( value ) torch . manual_seed ( value )
25 torch . cuda . manual_seed ( value )
torch . backends . cudnn . deterministic = True
 
 
init_random_seed ()
30
# пути к данным
data_path  =  ’./ drive / My Drive / COVID -19 _Radiography_Dataset ’ new_path  =  ’./ drive / My Drive ’
 
35
def  create_dataset ( src_path ,  target_path ,  tar_dir_name ,  mode =’ copy ’):
# Сначала сгружаем все патологии в одну папку all_diseases_path = os. path . join ( target_path , ’ All_pathologies
’)


os. mkdir ( all_diseases_path )
40  normal_path  =  os. path . join ( src_path ,  ’ Normal / images ’)
 
diseases_paths  =  [’ COVID / images ’,  ’ Lung_Opacity / images ’,  ’ Viral  Pneumonia / images ’]
for path in diseases_paths :
full_curr_path = os. path . join ( src_path , path )
45 file_names = os. listdir ( full_curr_path ) if  mode  ==  ’ copy ’:
for file_name in file_names :
shutil . copy ( os. path . join ( full_curr_path , file_name ), all_diseases_path )
else :
50 for file_name in file_names :
shutil . move ( os. path . join ( full_curr_path , file_name ), all_diseases_path )
 
# Создание соответствующих разделов
os. mkdir ( os. path . join ( target_path , tar_dir_name ))
55
train_dir = ’ train ’ val_dir = ’ val ’
class_names  =  [’ normal ’,  ’ pathology ’]
 
60 for dir_name in [ train_dir , val_dir ]: for class_name in class_names :
os. makedirs ( os. path . join ( target_path , tar_dir_name , dir_name , class_name ), exist_ok = True )
 
# Разделяем датасет на выборки
65 for i, file_name in enumerate ( tqdm ( os. listdir ( normal_path ))): if i % 5 != 0:
dest_dir =  os. path . join ( target_path ,  tar_dir_name ,  train_dir , ’ normal ’)
else :
dest_dir = os. path . join ( target_path , tar_dir_name , val_dir , ’ normal ’)
70  if  mode  ==  ’ copy ’:
shutil . copy ( os. path . join ( normal_path , file_name ), os. path . join ( dest_dir , file_name ))
else :
shutil . move ( os. path . join ( normal_path , file_name ), os. path . join ( dest_dir , file_name ))

75 for i, file_name in enumerate ( tqdm ( os. listdir ( all_diseases_path ))):
if i % 5 != 0:
dest_dir =  os. path . join ( target_path ,  tar_dir_name ,  train_dir , ’ pathology ’)
else :
dest_dir = os. path . join ( target_path , tar_dir_name , val_dir , ’ pathology ’)
80 shutil . move ( os. path . join ( all_diseases_path , file_name ), os. path . join ( dest_dir , file_name ))
 
os. rmdir ( all_diseases_path )
 
 
85 # Количество изображений в папке def get_images_numb ( path ):
return len ([ name for name in os. listdir ( path )])
 
 
90  create_dataset ( data_path ,  new_path ,  ’ data ’) dirs  =  [’ train ’,  ’ val ’]
class_names  =  [’ normal ’,  ’ pathology ’] for dir in dirs :
for class_name in class_names :
95 print (
dir  +  ’/’  +  class_name  +  ’:’  +  str ( get_images_numb ( os. path . join (’/ kaggle / working / data /’,  dir ,  class_name ))))
 
# Визуализация
fig = plt. figure ( figsize =(16 , 5))
100 fig . suptitle (" Pathology positive ", size =22)
img_paths  =  os. listdir (’/ kaggle / working / data / train / pathology ’) shuffle ( img_paths )
 
for i, image in enumerate ( img_paths [:4]) :
105  img  =  cv2 . imread ( os. path . join (’/ kaggle / working / data / train / pathology ’,  image ))
plt . subplot (1 , 4 , i + 1 , frameon = False ) plt . imshow ( img )
fig . show ()
 
110 # правила преобразования для train и val data_transforms = {
’ train ’:  transforms . Compose ([ transforms . Resize (299) ,

 

 
115
 
 
 
120

transforms . Center Crop (280) , transforms . Resize (224) , transforms . Random Equalize ( p =1) ,
transforms . Random Horizontal Flip () ,
#           transforms . Random Vertical Flip () , transforms . Random Rotation ( degrees =15) ,
#           transforms . Color Jitter ( hue =.1 , saturation =.1 , contrast = .5) ,
transforms . To Tensor () ,
transforms . Normalize ([0.485 , 0.456 , 0.406] , [0.229 , 0.224 ,
0. 225])
]) ,

 

125
 
 
 
130

’ val ’:  transforms . Compose ([ transforms . Resize (299) , transforms . Center Crop (280) , transforms . Resize (224) , transforms . Random Equalize ( p =1) , transforms . To Tensor () ,
transforms . Normalize ([0.485 , 0.456 , 0.406] , [0.229 , 0.224 ,
0. 225])

])
}
 
135 # преобразования изображений
data_dir  =  os. path . join ( new_path ,  ’ data ’)
 
data_images = { x: datasets . Image Folder ( os. path . join ( data_dir , x),
data_transforms [ x])
140       for  x  in  [’ train ’,  ’ val ’]}
 
batch_size = 16
# создание dataloaders для изображения
dataloaders = { x: torch . utils . data . Data Loader ( data_images [ x], batch_size = batch_size ,
145       shuffle =True , num_workers =2) for  x  in  [’ train ’,  ’ val ’]}
 
dataset_sizes  =  { x:  len ( data_images [ x])  for  x  in  [’ train ’,  ’ val ’]}
class_names  =  data_images [’ train ’]. classes
150
 
def imshow ( inp , title = None ):

 

 
155
 
 
 
160

""" Imshow for Tensor . """
inp = inp. permute (1 , 2 , 0). numpy ()
mean = np. array ([0.485 , 0.456 , 0. 406])
std = np. array ([0.229 , 0.224 , 0. 225]) inp = std * inp + mean
inp = np. clip ( inp , 0 , 1) plt . imshow ( inp )
if title is not None :
plt . title ( title )
plt . pause ( 0. 001)  # pause a bit so that plots are updated

 
 
165  X_batch ,  y_batch  =  next ( iter ( dataloaders [’ train ’])) imgs_numb = 3
out = torchvision . utils . make_grid ( X_batch [: imgs_numb ])
imshow ( out , title =[ class_names [ x] for x in y_batch ][: imgs_numb
])
 
170  device  =  torch . device (’ cuda :0 ’  if  torch . cuda . is_available () else  ’ cpu ’)
print ( torch . cuda . is_available ())
 
 
def train_model ( model , loss , optimizer , scheduler , num_epochs )
:
175 since = time . time ()
 


 
180
 
 
 
185
 
 
 
190

best_model_wts = copy . deepcopy ( model . state_dict ()) best_epoch = 0;
best_acc = 0.0; best_loss = np. inf hist_loss_train = []; hist_acc_train = []; hist_loss_val = []; hist_acc_val = []
 
# перебираем эпохи
for epoch in range ( num_epochs ):
print (’-’  *  10)
print (’ Epoch  {}/{} ’. format ( epoch ,  num_epochs  -  1))
 
# Each epoch has a training and validation phase for  phase  in  [’ train ’,  ’ val ’]:
if  phase  ==  ’ train ’:
#                     scheduler . step ()

 
195
model . train ()
 
 
else :
 
model . eval ()
 
200
running_loss = 0.
running_acc = 0.
 
 
# или 0
 
 
for inputs , labels in tqdm ( dataloaders [ phase ]):
 
inputs
= inputs . to( device )
 
205
labels
= labels . to( device )
 
# zero
the parameter gradients
 
optimiz
er . zero_grad ()
 
# forwa
rd + track history only in train
210
with to
rch . set_grad_enabled ( phase  ==  ’ train ’):
 
preds =
model ( inputs )
 
preds_c
lass = preds . argmax ( dim =1)
 
loss_va
lue = loss ( preds , labels )
215
 
# backw
 
ard + optimize only if in training phase
 
if phas
e  ==  ’ train ’:
 
loss_va
lue . backward ()
 
optimiz
er . step ()
220
 
# stati
 
stics
 
running
_loss += loss_value . item () * inputs . size (0)
 
running
_acc += ( preds_class == labels . data ). sum (). item ()
 
225
if phas schedul
e  ==  ’ train ’: er . step ()
 
epoch_l
oss = running_loss / dataset_sizes [ phase ]
 
epoch_a
cc = running_acc / dataset_sizes [ phase ]
230
 
print (’
 
{}  Loss :  {:.4 f}  Acc :  {:.4 f}’. format (
 
phase ,
epoch_loss , epoch_acc ))
 
if phas
e  ==  ’ train ’:
 
hist_lo
ss_train . append ( epoch_loss )
 
235
hist_ac
else :
c_train . append ( epoch_acc )
 
hist_lo
ss_val . append ( epoch_loss )
 
hist_ac
c_val . append ( epoch_acc )
 
# deep
copy the model





240
 
 
 
 
245

if phase == ’ val ’ and epoch_loss < best_loss :
print (’ Val  loss  Decreased  from  {:.4 f}  to  {:.4 f}  \ n Saving Weights ...  ’. format ( best_loss ,  epoch_loss ))
best_acc = epoch_acc best_loss = epoch_loss best_epoch = epoch
best_model_wts = copy . deepcopy ( model . state_dict ()) print ()

 
model . eval ()
time_since = time . time () - since
250  print (’ Training  complete  in  {:.0 f} m  {:.0 f} s’. format ( time_since // 60 , time_since % 60) )
print (’ Best  epoch :{}  val  Loss :{:4 f}  Acc :  {:4 f}’. format ( best_epoch , best_loss , best_acc ))
 

 
255
 
 
 
 
 
 
 
260

# Show all statistics
plt . plot ( np. arange (0 , num_epochs , dtype = int ), hist_loss_train , ’-o’,  label =’ loss_train ’)
plt . plot ( np. arange (0 ,  num_epochs ,  dtype = int ), hist_loss_val , ’
-o’,  label =’ loss_val ’)
plt . plot ( np. arange (0 , num_epochs , dtype = int ), hist_acc_train , ’-o’,  label =’ acc_train ’)
plt . plot ( np. arange (0 ,  num_epochs ,  dtype = int ),  hist_acc_val ,  ’- o’,  label =’ acc_val ’)
plt . xlabel (" Epochs ") plt . legend ();
plt . title ( model . __class_____ name__ )
plt . show ()

 
# load best model weights
265 model . load_state_dict ( best_model_wts )
return model , [[ hist_loss_train , hist_loss_val ], [ hist_acc_train , hist_acc_val ]]
 
 

 
270
 
 
 
275

resnet 18 = models . resnet18 ( pretrained = True ) for param in resnet18 . parameters ():
param . requires_grad =  True num_features = resnet 18 . fc. in_features n_classes = 2
resnet 18 . fc = torch . nn. Linear ( num_features , n_classes ) resnet 18 = resnet 18 . to( device )


criterion = torch . nn. Cross Entropy Loss ()

 
optimizer = torch . optim . Adam ( resnet 18 . parameters () , lr =1.0 e -3)
 
280 scheduler = torch . optim . lr_scheduler . Step LR ( optimizer , step_size =7 , gamma =0.1)
 
# запускаем обучение
resnet18 , history 18 = train_model ( resnet18 , criterion , optimizer , scheduler , 30)
 
285
# Метрики
 
 
def predict ( model , dataloader ):
 
model . eval ()
 
y_pred_list = []
 
290
y_true_list = []
with torch . no_grad ():
 
for  inputs ,  labels  in  tqdm ( dataloader [’ val ’],
leave = False ):
 
pred = model ( inputs . to( device ))
 
 
_, pred = torch . max ( pred , dim = 1)
 
 
295
labels . to( torch . device (" cpu "))
pred . to( torch . device (" cpu "))
 
 
y_true_list . extend ( labels . tolist ());
 
 
y_pred_list . extend ( pred . tolist ());
 
 
return y_pred_list , y_true_list
 
300
 
 
 
 
305
 
y_pred_list , y_true_list = predict ( resnet18 , dataloaders ) print ( classification_report ( y_true_list , y_pred_list )) cm= metrics . confusion_matrix ( y_true_list , y_pred_list ) print ( cm)
disp = Confusion Matrix Display ( confusion_matrix =cm , display_labels = class_names )
disp . plot () plt . show ()
 
#  os. mkdir (’ models ’)
torch . save ( resnet 18 . state_dict () ,  ’ models / resnet18 . pt ’)

Приложение 2 Скрипт с моделью для серверной части (script.py)
 
 
 
import torch
from torchvision import transforms , models , datasets import os
5 import numpy as np
 
 
class Image Folder With Paths ( datasets . Image Folder ): def __getitem__ ( self , index ):
10 original_tuple = super ( Image Folder With Paths , self ). __getitem__ ( index )
path = self . imgs [ index ][0]
tuple_with_path = ( original_tuple + ( path ,)) return tuple_with_path
 
15
def make_predictions ( path_to_model , path_to_imgs ): resnet = models . resnet18 ()
num_features = resnet . fc. in_features n_classes = 2
20 resnet . fc = torch . nn. Linear ( num_features , n_classes ) checkpoint = torch . load ( path_to_model , map_location = torch .
device (’ cpu ’))
resnet . load_state_dict ( checkpoint ) resnet . eval ()
 
25 transform = transforms . Compose ([ transforms . Resize (299) , transforms . Center Crop (280) , transforms . Resize (224) , transforms . Random Equalize ( p =1) ,
30 transforms . To Tensor () ,
transforms . Normalize ([0.485 , 0.456 , 0.406] , [0.229 , 0.224 ,
0. 225])
])
 
test_dataset = Image Folder With Paths ( path_to_imgs , transform )
35 test_dataloader = torch . utils . data . Data Loader ( test_dataset , batch_size =1 , shuffle =False , num_workers =0)
 
resnet . eval ()

 
test_predictions = []
40 test_img_paths = []
for inputs , labels , paths in test_dataloader : with torch . set_grad_enabled ( False ):
preds = resnet ( inputs ) test_predictions . append (
45 torch . nn. functional . softmax ( preds , dim =1) [:, 1]. data . numpy ()) test_img_paths . extend ( paths )
 
test_predictions = np. concatenate ( test_predictions )
 
50 test_img = [ os. path . basename ( x) for x in test_img_paths ] predictions = [ round (y, 4) for y in test_predictions ] return ( dict ( zip( test_img , predictions )))
 
 
55  if  __name__  ==  ’ __main__ ’:
print ( make_predictions ( os. path . join ( os. getcwd () ,  ’ models ’,  ’ resnet 18 . pt ’),
os. path . join ( os. getcwd () ,  ’ public ’,  ’ uploads ’)))

Приложение 3
Серверная часть приложения(app.js)
 
 
 
const  express  =  require (’ express ’);
const  body Parser  =  require (’ body - parser ’); const multer     = require (" multer ");
5  const  path  =  require (’ path ’); const  fs  =  require (’ fs ’);
const  Adm Zip  =  require (’ adm - zip ’);
let  { Python Shell }  =  require (’ python - shell ’);
 
10 const PORT = process . env . PORT || 8081; const app = express ();
 
const files Dest = " public / uploads ";
// const json Parser = express . json ();
15
app . use ( body Parser . urlencoded ({ extended :  true  })); app . use ( express . static ( path . resolve ( __dirname ,  ’ public ’)));
 
app . get ("/" , function ( request , response ){
20      response . send File ( __dirname + " public / index . html ");
});
 
app . get ("/: file_name ", function ( request , response ){
response . send File ( __dirname + "/ public / uploads / Unknown /" + request . params . file_name );
25 });
 
// File names
const storage Config = multer . disk Storage ({ destination : ( req , file , cb) =>{
30           cb( null , files Dest );
},
filename : ( req , file , cb) =>{ cb( null , file . originalname );
}
35 });
 
// Filter
const file Filter = ( req , file , cb) => { if( file . mimetype === " image / png " ||
40      file . mimetype === " image / jpg "||


file . mimetype === " image / jpeg " || file . mimetype === " application / zip "){
cb( null , true );
}
45      else {
cb( null , false );
}
};
 
50 const upload = multer ({ storage : storage Config });
 
app . post (’/ predict Images ’,  upload . array (" files []") ,  function  ( request , response ){
clear Directory ( fs , path . join ( filesDest ,’ Unknown ’)); let filedata = request . files ;
55      // console . log ( filedata ); if (! filedata )
response . status (400) . send (’ Error !’); else
 
60       // create Directory ( fs , path . join ( filesDest ,’ Unknown ’)); move Files ( fs , filesDest , path . join ( filesDest ,’ Unknown ’)); Python Shell . run ( ’./ scripts / main . py ’,  null ,  function  ( err ,
results ) {
if ( err ) throw err ;
var  probs  =  JSON . parse ( results [0]. replace (/\ ’/ g , ’\" ’));
65            // clear Directory ( fs , path . join ( filesDest ,’ Unknown ’)); response . send ( probs );
});
});
 
70
app . post (’/ predict Archive ’,  upload . single (" archive ") ,  function ( request , response ){
clear Directory ( fs , path . join ( filesDest ,’ Unknown ’)); sleep (10) ;
let filedata = request . file ;
75      // console . log ( filedata ); if (! filedata )
response . status (400) . send (’ Error !’); else {
// create Directory ( fs , path . join ( filesDest ,’ Unknown ’));
80           var zip = new Adm Zip ( filedata . path );
zip . extract All To (’ public / uploads / Unknown ’, true );      delete File ( fs , path . join ( filesDest , filedata . originalname ));

 

 
 
85
 
 
}
90 });

Python Shell . run ( ’./ scripts / main . py ’,  null ,  function  ( err , results ) {
if ( err ) throw err ;
var  probs  =  JSON . parse ( results [0]. replace (/\ ’/ g , ’\" ’));
// clear Directory ( fs , path . join ( filesDest ,’ Unknown ’)); response . send ( probs );
});

 
 
app . listen ( PORT ,() =>{
console . log(’ Server  has  been  launched  on  port  ’  +  PORT );
95 });
 
process . on (" SIGINT ", async () => { console . log (" Server is down ."); process . exit ();
100 });

Приложение 4
Клиентская часть приложения(script.js)
 
 
 
$(’ document ’). ready ( function (){ const errors Codes = {
0:  ’  Пожалуйста ,  выберите  правильые  файлы.’,
5            1: ’ Не все из выбранных вами файлов имеют допустимое разре шение.’,
2: ’ Допустимо выбирать изображения с расширениями jpg , jpeg
, png или ОДИН архив с расширением zip ’
}
 
 
10
var error Type ;
 
 
const file Types = [
 
 
 
’ image / jpeg ’,
 
 
 
’ image / jpg ’,
 
 
 
15
’ image / png ’,
’ application / zip ’
 
 
 
]
 
 
 
function valid File Type ( file ) {
 
 
 
20
for ( var i = 0; i < file Types . length ;
if( file . type === file Types [ i]) {
i ++)
{
return true ;
}
}

 
25       }

return false ;

 
 
function return File Size ( number ) { if( number < 1024) {
30                 return  number  +  ’ bytes ’;
} else if( number > 1024 && number < 1048576 ) { return  ( number / 1024) . to Fixed (1)  +  ’ KB ’;
} else if( number > 1048576) {
return  ( number / 1048576 ) . to Fixed (1)  +  ’ MB ’;
35            }
}
 
 
function make Diagnosis ( numb ){

40           if( numb >=0. 5) {
return  ’-  патология  (’  +  numb  +  ’) ’;
}
else {
return  ’-  без  патологий  (’  +  numb  +  ’) ’;
45            }
}
 
 
function show Result ( result ){
50           // console . log ( result );
$(’# preview ’). empty ();
var  list  =  document . create Element (’ ol ’);
$(’# preview ’). append ( list );
// var res = JSON . parse ( result );
55           $. each ( result , function (k, v) {
var  list Item  =  document . create Element (’ li ’); var  para  =  document . create Element (’ p ’);
para . text Content = k;
var  image  =  document . create Element (’ img ’);
60                $. ajax ({
url :  ’/’+k,
method : " GET ", xhr Fields : {
response Type : ’ blob ’
65                     },
success : function ( response ){
// console . log ( response );
image . src = URL. create Object URL ( response );
},
70                     error : function ( e){ console . log( e);

 
 
75
 
 
 
80       }

}
});
list Item . append Child ( image );
para . text Content += make Diagnosis ( v); list Item . append Child ( para );
list . append Child ( list Item );
});
$(’# images_upload ’). val (’ ’);


// Обработчик  кнопки  " Удалить  файлы"
$(’# cancel ’). click ( function (){
$(’# images_upload ’). val (’ ’);

85            $(’# images_upload ’). change (); error Type = undefined ;
})
 
 
90       // Обработчик изменения input
$(’# images_upload ’). change ( function (){
$(’# preview ’). empty ();
 
var curr Files = $( this ) [0]. files ;
95           if( curr Files . length == 0){
$(’# preview ’). append (  " <h4 >В  настоящее  время  файлы  для  з агрузки не выбраны </ h4 >" );

 
 
100
 
 
 
 
105
 
 
 
110

}
else {
var  list  =  document . create Element (’ ol ’);
$(’# preview ’). append ( list );
for ( var i = 0; i  <  curr Files . length ; i ++) { var  list Item  =  document . create Element (’ li ’); var  para  =  document . create Element (’ p ’);
para . text Content  =  curr Files [ i]. name  +  ’,  ’  + return File Size ( curr Files [ i]. size )  +  ’  -  ’;
if( valid File Type ( curr Files [ i])) {
var  image  =  document . create Element (’ img ’); if( curr Files [ i]. type  ==  ’ application / zip ’){
image . src  =  ’../ images / archive . png ’; if( curr Files . length != 1)
error Type = 2;
}
else {
image . src = window . URL . create Object URL ( curr Files [ i
]);

}
115                          list Item . append Child ( para ); list Item . append Child ( image );
}
else {
para . text Content   +=  ’ неверное  расширение  файла!’;
120                          para . class List . add (" error "); list Item . append Child ( para ); error Type = 1;
}
list . append Child ( list Item );
125                }
}

 
});
 
 

130
 
 
 
135


 
// Отправка данных на сервер
// http :// 127 . 0 . 0 . 1 : 8081
$(’# send ’). click ( function  (){
curr Files  =  $(’# images_upload ’) [0]. files ; if( error Type ){
alert ( errors Codes [ error Type ] + errors Codes [0]) ;

}
else if ( curr Files . length == 0){
alert (’ Выберите  файлы  для  отправки ’);

140
 
 
 
 
145

}
else {
var formdata = new Form Data ();
if( curr Files . length == 1 && curr Files [0]. type == ’ application / zip ’){
formdata . append (’ archive ’, curr Files [0]) ;
$. ajax ({
url  :  ’/ predict Archive ’, method  :  ’ POST ’,
headers : {
’ Access - Control - Allow - Origin ’:  ’*’

150
 
 
 
155

},
cache : false , process Data : false , content Type : false , data : formdata ,
success : function ( result ){ show Result ( result );

},
error : function ( e){ console . log( e);
160                          }
});
}


165
 
 
 
170

else {
$. each ( currFiles , function (i, file ){ formdata . append (’ files []’ , file );
});
$. ajax ({
url  :  ’/ predict Images ’, method  :  ’ POST ’, headers : {

 
’ Access - Control - Allow - Origin ’:  ’*’
},
cache : false , process Data : false ,
175                          content Type : false , data : formdata ,
success : function ( result ){ show Result ( result );
},
180                          error : function ( e){ console . log( e);

 
 
185


 
}
}
});
});

}
});
