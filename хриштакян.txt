 РЕФЕРАТ

На 52 с., 13 рисунков, 4 приложения.
КЛЮЧЕВЫЕ СЛОВА: УПРАВЛЕНИЕ ГОЛОСОМ, СИСТЕМЫ РАСПОЗНАВАНИЯ РЕЧИ, API, C#, ASP.NET CORE, WEB.
Тема данной работы: “Разработка сервиса получения информации об успеваемости учащихся с использованием системы распознавания”.
В данной работе проведен обзор и сравнение существующих систем распознавания речи, на основе тестов выбрана модель для дальнейшей работы. Проведен обзор используемых технологий. Реализованы модули транскрибации, сопоставления, обработки данных, модуль работы с текстовыми файлами форматов JSON и XML. С интеграцией данных модулей разработан Web API с использованием языка C# на платформе ASP.NET Core, создана и интегрирована документация API, проведено тестирование разработанного сервиса.

ВВЕДЕНИЕ
Речь, на сегодняшний день, является неотъемлемой частью общества. Она позволяет более быстро доносить необходимую информацию, так как проговорить фразу или даже целую лекцию бывает быстрее и удобнее, чем ее прочитать. Не стоит забывать и о том, что такой способ обмена информацией для человека является гораздо привычнее, так как членораздельная речь как способ взаимодействия является частью человеческой культуры уже около 2 миллионов лет.
Именно поэтому, с развитием технологий, люди решили научить технику понимать нашу речь. В последствии это привело к созданию и развитию систем распознавания речи. Само по себе распознавание речи – это технология преобразования человеческой речи в текст, которая ежедневно помогает сотням людей ускорить время выполнения рутинных вещей: внести заметку в календарь, установить будильник, запросить маршрут в навигаторе. Системы распознавания можно интегрировать и настраивать для работы с, практически, любой сферой жизни.
Для работников образовательной сферы, например школьных преподавателей, актуальным вопросом является упрощение выставления оценок ученикам в классах. С введением систем электронных журналов этот процесс немного упростился, так как все классы и ученики в них теперь находятся в одной базе данных. Но выставление оценок все также остается рутинным, монотонным процессом, с необходимостью искать нужного ученика в списке, искать нужную ячейку с нужной датой и выставлять нужную отметку.
Целью данной работы является разработка и тестирование сервиса получения информации об успеваемости учащихся с использованием системы распознавания. Для достижения цели необходимо решить следующие задачи:
–	провести обзор существующих систем распознавания речи, выбрать системы для дальнейшего анализа;
–	провести обзор используемых технических средств;
 
–	протестировать выбранные системы распознавания, выбрать оптимальную, на ее основе реализовать модуль транскрибации для сервиса;
–	выполнить реализацию вспомогательных модулей сервиса;
–	используя созданные модули разработать и реализовать web API;
–	провести тестирование разработанного сервиса, сравнить с аналогами.
В первой главе данной работы приведена общая теория распознавания речи и проведен обзор существующих систем распознавания. Во второй главе описаны используемые технические средства. В третьей главе описана реализация модуля транскрибации для разрабатываемого сервиса. В четвертой главе приведено описание реализации вспомогательных модулей для сервиса. В пятой главе описана разработка Web API сервиса. В шестой главе проведено тестирование сервиса и приведены результаты.
 
ГЛАВА 1. ОБЗОР СИСТЕМ РАСПОЗНАВАНИЯ РЕЧИ

В качестве системы распознавания в данной работе будет использоваться система распознавания речи, так как благодаря интеграции данной системы можно существенно облегчить задачу выставления оценок преподавателям. В данной главе будет рассмотрена теоретическая часть распознавания речи, выбор и обзор рассматриваемых систем.

1.1.	Теория распознавания речи

Важным этапом в развитии алгоритмов распознавания являются 1960-е годы. В этот период был разработан алгоритм динамической трансформации временной шкалы (сокращенно DTW), который позволил системе распознавать отдельно сказанные слова в беглой речи. На основе данного алгоритма проектировались системы со словарями из 200 слов, однако все они имели существенный недостаток – способ обработки самой речи.
Для лучшего понимания данного недостатка, стоит рассмотреть лингвистическую и фонетическую проблемы распознавания речи. Очевидно, что достаточно затруднительно найти хотя бы двух людей, которые говорят абсолютно одинаково, с одинаковыми тембром, интонацией, произношением. В основу распознавания речи закладывается принцип сопоставления. Изначально, машину “обучали” сопоставлять определенные слова, сказанные определенным человеком определенным образом, с ее словарем, в котором эти же слова, сказанные этим же диктором, уже разобраны на математическую модель и могут сравниваться с поступающим сигналом. Однако, такой подход был крайне неэффективен, так как он сильно зависел от диктора. Смена человека, диктующего команды, на другого, могла понизить частоту правильного распознавания вполовину [6]. Стало ясно, что нужно бороться с данной проблемой и было принято решение о смене искомой единицы в поступающем сигнале. Если изначально, в исходящей звуковой волне искали звуковое пятно,
 
являющееся словом, то теперь стали разрабатывать систему, которая искала бы в сигнале фонемы [9]. Фонема – это звуковая единица, которой транскрибируется произнесенная буква произнесенного слова в текст [10].
К 1980 была спроектирована система на основе распознавания фонем и словарем в 20000 слов, что было серьезным прогрессом в области. Настолько увеличить словарь, при этом не потеряв точность распознавания и без привязки к определенному диктору, позволило применение алгоритма скрытой марковской модели [16]. Эта статистическая модель позволяет предугадывать неизвестные элементы модели на основе известных, что в случае распознавания речи позволило с высокой точностью предугадывать неразобранные элементы сигнала на основе тех, что были преобразованы в текст.
Также изменился и принцип самой обработки входящего сигнала, который используется и по сей день. Итоговый файл, содержащий записанный звук, делится на фрагменты (фреймы) определенной длины с определенным шагом. На основе опытов были вычислены оптимальные значения: 25 миллисекунд фрагменты с шагом в 10 миллисекунд. Таким образом получаются фрагменты “внахлёст” друг друга, что повышает вероятность корректного разбора фонем [5].
Затем	были	разработаны		первые	рекуррентные	нейронные	сети	с интегрированной архитектурой долгой краткосрочной памяти для обучения системы	понимать		контекст	сказанного,	чтобы	лучше	предугадывать нераспознанные элементы [2]. Данные системы пользуются популярностью и по сей день, благодаря своей гибкой настройке и высокой точности распознавания. Глубокое и всестороннее рассмотрение различных аспектов теории и практики распознавания речи с описанием всех алгоритмов и возможностями их применения описаны в работе Xuedong Huang, Alex Acero, Hsiao-Wuen Hon “Spoken language processing. A guide to theory, algorithm, and system development”
[20].
 
1.2.	Обзор выбранных решений

За несколько десятков лет проводимых исследований, попыток интеграций, разработок более совершенной системы, открытия алгоритмов и их применений, было создано множество систем распознавания речи. Решения, рассматриваемые в данной работе, были выбраны относительно частоты встречаемости их использования в разработках, упоминаниях в статьях и работах, а также их поддержке и актуальности на сегодняшний день [6; 7]. Рассматриваться будут 5 систем: Vosk API, Kaldi, Yandex Speech Kit, Google Cloud Speech-to-Text, Azure Stt.

1.2.1.	Vosk API

Vosk API – это библиотека с открытым исходным кодом распознавания речи, которая способна работать с более чем 20 языками, среди которых есть русский и английский [23]. Также, данная библиотека может работать автономно, без постоянного подключения сети, в том числе и на мобильных устройствах. У данного проекта есть широкий спектр моделей распознавания, среди которых есть, так называемые, “компактные” модели, вес которых занимает около 50Мб, так и гораздо большие по объему модели за гигабайт, обеспечивающие большую точность. Vosk дает возможность пользователям самостоятельно доучивать систему на распознавание специфической лексики, а также поддерживает интеграцию с популярными языками, такими как Java, Python, C#, JavaScript. Vosk, как заявляют разработчики, является библиотекой практической, с уже заявленным набором механик, сценариев использования, моделей. Она совмещает в себе множество решений, однако базируется на другой библиотеке распознавания голоса Kaldi, которая также рассматривается в работе дальше.
 
1.2.2.	Kaldi

Kaldi является инструментарием с открытым исходным кодом для распознавания речи который, как утверждают разработчики, подойдет как основа для исследований данной сферы [21]. В этом состоит их существенная с Vosk разница, которую необходимо учитывать при выборе используемого решения для проекта. Рассматривая Kaldi, стоит обратить внимание на используемые в ней алгоритмы. Так, вместо распространенного метода обучения на базе N-грамм, здесь используются алгоритмы, основанные на рекуррентных нейронных сетях и реализованные во фреймворке RNNLM (Recurrent Neural Network Language Modelling). В качестве алгоритма извлечения признаков из звукового сигнала используется мел-частотные кепстральные коэффициенты.
По умолчанию, Kaldi поддерживает только английский язык, однако ее можно обучать на корпусах множества языков, включая русский.

1.2.3.	Yandex Speech Kit

Система распознавания речи, разработанная корпорацией Яндекс, входит в перечень облачных сервисов. Представляет собой сервис речевых технологий с закрытым исходным кодом. Голосовой помощник “Алиса” от Яндекса основана на данном сервисе. Данное решение предоставляет услуги не только по распознаванию речи, но и по синтезу. Для обмена данными производится обращение с помощью HTTP запросов, в которых пользователь передает либо текст для дальнейшего синтеза речи на его основе, либо аудиофайл со звуковой дорожкой, в которой необходимо распознать и транскрибировать текст. Ответы также отправляются в качестве HTTP ответа. Соответственно, данный сервис требует от пользователя постоянное подключение к интернету, чтобы взаимодействовать. Несмотря на закрытый исходный код, Яндекс предоставляет возможность дообучить модель распознавания для ваших нужд. В связи с политикой конфиденциальности компании и политикой сохранения права
 
интеллектуальной собственности, используемые в реализации принципы и алгоритмы не разглашаются. Для работы с данным сервисом необходимо приобретать подписку, однако имеется пробная версия для тестирования и ознакомления с технологией.

1.2.4.	Google Cloud Stt

Облачная технология распознавания речи с закрытым исходным кодом от корпорации Google. Технология основана на ИИ Google. Имеется возможность выбора заранее обученной модели для распознавания, среди которых есть специфические модели для лучшего распознавания телефонных звонков, медицинских терминов, речи из видеороликов. Поддерживается большинство распространенных языков, включая русский. Для взаимодействия с ней предоставляется 2 разных варианта: с помощью API, либо с помощью работы с STT-консолью. Если возможностей распознавания заранее подготовленных моделей недостаточно для нужд пользователя, есть возможность дообучения модели распознавания. Также поддерживается возможность распознавания речи на нескольких языках в одном файле. Для работы с данным сервисом необходимо приобретать подписку, однако также имеется и бесплатная пробная версия для ознакомления с возможностями технологии. Так как данная интеллектуальная собственность защищена лицензией и политикой конфиденциальности, используемые методики и алгоритмы также не разглашались.

1.2.5.	Azure Stt

В числе коллекций сервисов от компании Microsoft, есть службы облачных вычислений, называемые Azure. Среди служб данного облачного сервиса есть и служба “Речь”, частью которой является Azure Stt – система транскрибирования аудио в текст. Поддерживает более чем 85 языков, включая русский и
 
английский. Имеет возможность самонастройки модели для повышения точности распознавания специфической лексики определенной области, необычных акцентов, нестандартно шумного окружения. Также, данный сервис способен проводить поиск и аналитику по обрабатываемому тексту. Поддерживает интеграцию со многими языками программирования и в различных форматах. Для работы с Azure Stt можно воспользоваться API, специальным Speech SDK, либо же интерфейсом командной строки службы “Речь”. Распространяется данная служба по подписке, однако имеет двенадцатимесячный пробный период с возможностью ознакомления с почти полным функционалом платформы. Из соображений конфиденциальности и неразглашения рабочей тайны, компания не указывает, на основе каких алгоритмов и подходов разработан их сервис.

1.3.	Задача нахождения меры схожести строк

Так как система распознавания речи не может гарантировать абсолютно точное, безошибочное распознавание, вместе с такими системами используются алгоритмы, позволяющие устранять недочеты и неточности в получившихся результатах. Если при распознавании есть некие исходные данные, среди которых нужно найти распознанные элементы и сопоставить их, принято использовать алгоритмы нахождения меры схожести строк. По своей сути, задача следующая: необходимо найти из фактических строк ту, которая наиболее похожа на распознанную.
Для решения данной задачи было придумано несколько алгоритмов, в данной работе используется алгоритм Джаро-Винклера.
Данный алгоритм был предложен в 1999 году Уильямом Э. Винклером как модификация алгоритма Джаро [3]. В своей основе лежит та же идея, что была использована Левенштейном в его алгоритме, то есть определить количество односимвольных операций, которые необходимо провести над строкой 1, чтобы получить строку 2. Значение расстояния находится в диапазоне от 0 до 1, в
 
зависимости от реализации означающие либо полное сходство, либо отсутствие сходства. Серьезные отличия возникают в подходе к подсчету односимвольных операций. Расстояние Джаро между двумя строками может быть найдено по формуле:
 
𝑑j = {1 ( 𝑚
 
0,	когда 𝑚 = 0
+ 𝑚 + 𝑚 − 𝑡) , в остальных случаях ,	(1.1)
 
3   |𝑠1|	|𝑠2|	𝑚
где 𝑠1 - длина первой строки;
𝑠2 - длина второй строки;
𝑚 – число совпадающих символов;
𝑡 – половина числа транспозиций.
При этом два символа из строк 𝑠1 и 𝑠2 будут считаться совпадающими только в том случае, если сами символы являются одинаковыми и расстояние между ними в строках не превышает значение, получаемое следующей формулой:
max (|𝑠1|, |𝑠2|)
቞	2	] − 1.	(1.2)

Например, при сравнении двух слов, КЛЮЧ и ЧУЛОК, буквы К и Ч не будут считаться совпадающими, так как значение по формуле (1.2) для данных строк будет равно 1, что меньше, чем расстояние между данными символами в строках.
Сходство Джаро-Винклера строится как модификация, поэтому в основе своих вычислений использует алгоритм Джаро и может быть найдено по формуле:
𝑑w = 𝑑j + (𝑙𝑝(1 − 𝑑j)),	(1.3) где 𝑑j – расстояние Джаро, формула (1.2);
𝑙 – длина общего префикса от начала строки до максимума четырех символов;
𝑝 – постоянный коэффициент масштабирования.
 
Именно благодаря коэффициенту масштабирования данный алгоритм подходит для корректировки распознавания речи больше, чем алгоритм Дамерау-Левенштейна, который предполагалось использовать изначально. Данный коэффициент служит для корректировки оценки расстояния в большую сторону, чтобы найти общие префиксы в словах. При этом, данный коэффициент не является константой и может быть изменен, но есть ограничение сверху, нельзя превышать значение в 0.25, иначе есть вероятность того, что сходство может стать больше порогового значения. Сам Винклер, в своей работе, использовал 𝑝 = 0.1 , что в большинстве случаев является оптимальным значением. Исходный код с реализацией данного алгоритма приведен в П4.8 приложения 4.
Алгоритм Дамеру-Левенштейна, в свою очередь, считает лишь количество операций вставки, удаления, замены и перестановки, что может повлечь за собой некорректный результат, так как у учеников однофамильцев, но с разными именами, может быть ситуация, при которой имя одного распознается некорректно и количество операций, чтобы привести эту строку к другому ученику будет меньше.

1.4.	Выводы

В данной главе была приведена теория распознавания речи, основные вехи развития технологии и алгоритмов. Также были определены системы, для анализа, каждая из которых была описана. Помимо этого, в главе был описан алгоритм решения задачи нахождения меры сходства строк, который используется совместно с системами распознавания речи для нивелирования неточных результатов.
 
ГЛАВА 2. ОБЗОР ТЕХНИЧЕСКИХ СРЕДСТВ

В данной главе будут описаны используемые при реализации технические средства. Для создания Web API будет использоваться платформа ASP.NET Core и язык программирования C#, разработка будет происходить в IDE Rider. В качестве архитектурного подхода будет реализовываться REST, для интеграции документации и ознакомительного веб-интерфейса будет использоваться Swagger.

2.1.	Язык C# и Rider

Проект реализуется на языке программирования C#. Данный язык, на сегодняшний день, является одним из самых востребованных и популярных в IT- отрасли. Благодаря своей гибкости, на нем разрабатываются самые разнообразные приложения, от обычных десктопных программ до веб-сервисов с ежедневной нагрузкой в миллионы пользователей.
Благодаря такой популярности язык очень быстро развивается, постоянно поддерживается командой разработчиков, для него выходит множество сторонних библиотек.
Стоит упомянуть, что C# не существовал бы без платформы .NET. Она также является одной из причин популярности данного языка. Данная платформа обеспечивает кроссплатформенную и переносимую разработку, обеспечивает разработчика обширной библиотекой классов, которая постоянно пополняется, дает возможность использования разнообразных технологий, таких как ADO.NET и Entity Framework.
Самым главным аргументом в пользу использования данного языка была производительность. Приложения, разработанные на платформе .NET, в целом, выгодно отличаются от других своей быстрой работой [15].
Для более удобной разработки использовалась IDE Rider. Данная IDE разработана компанией JetBrains для .NET разработки. Rider позволяет работать
 
с множеством типов приложений .NET, включая веб-сервисы, имеет поддержку ASP.NET Core и работы с системой контроля версий GIT, а также отличается высокой скоростью как загрузки проектов, так и работы с ними.

2.2.	Платформа ASP.NET Core

Для разработки веб-приложений и сервисов на языке C# самой распространенной платформой является ASP.NET Core.
ASP.NET Core – это популярная open-source платформа веб-разработки для создания веб-приложений на платформе .NET. Данная платформа спроектирована так, чтобы создавать модульные приложения [13]. Такой подход имеет следующие преимущества:
–	разрабатываемые приложения получаются более легковесными, так как имеют только необходимые компоненты,
–	есть возможность самостоятельно выбирать компоненты конвейера,
–	есть возможность создавать собственные компоненты и добавлять их в конвейер,
–	присутствуют варианты выбора платформы для размещения приложения. ASP.NET Core предоставляет платформу веб-разработки, основанную на шаблоне Model-View-Controller (MVC). Кроме того, она включает в себя платформу Razor Pages, которая предназначена для разработчиков, которые лучше знакомы с подходом к созданию веб-приложений, ориентированным на работу и взаимодействие с веб-страницами, но также поддерживает и подход
Minimal API.
ASP.NET Core также включает в себя платформу для разработки веб- сервисов на основе REST (Web API) [12; 4]. Также ведется работа по включению платформы на основе веб-сокетов (SignalR), которая позволит обновлять содержимое страницы в режиме реального времени, инициируемое сервером.
 
Также, ASP.NET Core является кроссплатформенным, поддерживая Windows, Linux и Mac. Является быстрым в выполнении из-за работы с пакетами, что обеспечивает сокращение конвейера запросов.

2.3.	Архитектура REST

Так как данный сервис, в первую очередь, разрабатывается для того, чтобы, в дальнейшем, интегрировать работу с ним в различные системы электронного оценивания учеников, таких как, например, электронные журналы, необходимо реализовать наиболее удобную архитектуру взаимодействия.
Именно для таких целей был разработан архитектурный подход REST – подход передачи состояния представления. Он позволяет выстроить разрабатываемый API так, чтобы использовался протокол HTTP, который будет выступать в качестве вида запроса к серверу. У REST есть несколько основополагающих принципов:
–	разделить в сущностном отношении клиент и сервер;
–	не использовать и не получать информации о состоянии клиента;
–	организовать для работы с пользователем единый интерфейс;
–	сделать для пользователя единую точку входа на сервер.
Для	простой	и	гибкой	реализации	с	полноценным	функционалом используются стандартные функции HTTP, к которым относятся:
–	GET, для получения информации от сервера;
–	POST, для отправления данных на сервер;
–	PUT, для обновления информации на сервере;
–	DELETE, для удаления информации с сервера.
Все перечисленные характеристики архитектуры REST сделали данный подход наиболее используемым на сегодняшний день.
 
2.4.	Swagger

Swagger, по сути, является UI для OpenAPI, который позволяет создавать спецификацию и документацию, описывающую создаваемую API, напрямую читая ее структуру [24]. То есть, прочитав структуру разрабатываемого API, Swagger может автоматически генерировать интерактивную документацию к нему. Реализовано это с помощью запроса к API, в ответ на который отправляется файл в формате YAML или JSON, содержащий подробную структуру. Генерируемый файл, при этом, отвечает стандартам спецификации OpenAPI. Спецификация Open API — это формат описания API для REST API [22]. Файл OpenAPI позволяет описывать API, включая: доступные конечные точки и операции на каждой конечной точке, ввод и вывод рабочих параметров для каждой операции, методы аутентификации, контактная информация, лицензия, условия использования и другая информация.

2.5.	Выводы

В данной главе были описаны причины выбора языка C# и IDE Rider. Также была описана платформа ASP.NET Core, которая будет использоваться для построения веб-сервиса. Описана выбранная архитектура REST, являющаяся одним из самых распространённых архитектурных подходов на сегодняшний день. Также приведено описание спецификации OpenAPI, являющаяся стандартом для описания API, и Swagger, который используют данную спецификацию для создания виртуальной документации.

ГЛАВА 3. РЕАЛИЗАЦИЯ МОДУЛЯ ТРАНСКРИБАЦИИ

Для реализации данного модуля необходимо выбрать, на основании какой системы он будет работать. В данной главе будет проведено тестирование выбранных в параграфе 1.2 систем распознавания речи, определена оптимальная
 
из них, с которой будет проводиться реализация модуля транскрибации. Затем описана реализация модуля, проведено и его тестирование.

3.1.	Тестирование и анализ систем распознавания

Сравниваться системы будут по следующим критериям: используемый алгоритм извлечения признаков, поддерживаемые языки, скорость обработки, точность распознавания. Для определения метрики точности распознавания воспользуемся общепринятой метрикой Word Error Rate (WER) [1]. Данная характеристика вычисляется по следующей формуле:
𝑆 + 𝐷 + 𝐼
 
𝑊𝐸𝑅 =

где S – количество замен слов;
D – количество удалений слов; I – количество вставок слов;
N – количество слов в исходной фразе.
 
𝑁	,	(3.1)
 
В качестве измерения скорости обработки будет измеряться временной промежуток между двумя точками: отправка аудиофайла с текстом на обработку и получение результата обработки, так как данный временной промежуток будет также важен при разработке сервиса.
Далее определяется конкретная методология, по которой выбранные системы будут анализироваться и сравниваться. Тестов, которые будут проходить системы, будет три: распознавание речи из файла с зачитанным, заранее подготовленным фрагментом текста на общую тематику, распознавание речи из аудиофайла с подкастом с платформы YouTube на общую тему, транскрибирование вырезанного фрагмента аудиокниги. Зачитывание текста будет записано двумя людьми с разными голосами для более точного результата работы систем при разных дикторах и условиях записи аудиофайла. При выборе содержимого для записи, будут выбраны тексты на общую тематику, с минимально возможным количеством специальной речи и терминов, чтобы
 
симулировать среднестатистическую речь человека в обычной среде. Также, такой набор данных оправдывается и тем, что каждая из систем обучена хоть и массивными и исчерпывающими речевыми корпусами, однако даже такие речевые корпусы не предназначены для системы, которая бы использовалась в узконаправленной области с большим количеством специфической лексики. Язык текстов будет русским, однако, при сравнении систем, будет учитываться их возможность работы с другими языками.
Запись с микрофона производится в одноканальном формате, 32 бита, 32000Гц. Исходный звук из аудиодорожки видео и аудиофайла аудиокниги останутся в первозданном виде, как он представлен пользователям. Сами файлы не будут проходить процедуры очистки от шумов и выравнивания громкости, чтобы максимально приблизить тестирования к реальной ситуации пользования сервисом.
Технология исследования будет следующая: были заранее записаны аудиофайлы, которые необходимо транскрибировать, текст для записи зачитывался мужчиной и женщиной в течение 1 минуты. В качестве текста был взят диктант по русскому языку для детей 5 класса. В качестве подкаста с YouTube было взято видео с канала “ТЕД на русском” под названием “Как видеоигры влияют на мозг / #ТЕДсаммари” длительностью 10 минут 24 секунды. Речь в данном видеоролике, в основном, на русском, с обыденной лексикой, однако присутствуют некоторые слова или словосочетания на английском языке, которые будут учтены при вычислении WER. В качестве фрагмента аудиокниги используется файл, длительностью 7 минут 27 секунд, в котором читается фрагмент книги Аркадия Натановича Стругацкого и Бориса Натановича Стругацкого “Пикник на обочине”. Фрагмент озвучен многоголосо, с разными тональностями и интонациями. Все аудиофайлы записаны с частотой 32кГц в режиме моно. Также, присутствует ограничение, которое накладывается из-за использования демоверсий коммерческих продуктов, а именно невозможность обрабатывать в таких сервисах (Google Stt и Yandex Speech Kit) аудиофайлы
 
длиной более 1 минуты. Было принято решение взять пятиминутные фрагменты из видео подкаста и аудиокниги, разбить их на 5 файлов по 1 минуте и работать с ними. В дальнейшем именоваться данные файлы будут с указанием порядкового номера фрагмента, к примеру Книга_1, Тед_1. Как Диктор_1 обозначим диктора-мужчину, как Диктор-2 – диктора-женщину. Таким образом, будет проверено 5 файлов с подкастом, 5 файлов с аудиокнигой, 1 файл с зачитанным мужчиной текстом и 1 файл с зачитанным женщиной текстом.
При тестировании Vosk API использовалась компактная модель. Результаты тестирования представлены в табл.П1.1 приложения 1, результаты тестирования Kaldi представлены в табл.П1.2 приложения 1, результаты тестирования Yandex Speech Kit представлены в табл.П1.3 приложения 1, результаты тестирования Google Cloud Stt представлены в табл.П1.4 приложения 1, результаты тестирования Azure Stt представлены в табл.П1.5 приложения 1.

3.2.	Выбор системы распознавания

Для удобства сравнения, усредненная информация о системах на основе документации и проведенных тестов приведена в табл.П1.6 приложения 1.
Каждая система распознавания поддерживает как популярные языки, такие как английский и русский, так и сложные для распознавания языки, как китайский, японский и арабский и множество других. Однако, в коммерческих системах, для смены языка распознавания, достаточно сменить переменную, указывающую языковую модель, а в Vosk и Kaldi нужно будет скачивать на ваше устройство определенную модель для использования.
В качестве алгоритма извлечения признаков системы, в которых данная информация открыта для общего доступа, используются мел-частотные кепстральные коэффициенты, принятые на сегодняшний день оптимальным по эффективности и скорости алгоритмом. О коммерческих системах информация отсутствует.
 
Относительно скорости работы наиболее быстрыми являются системы, работающие на машине пользователя, то есть Vosk и Kaldi, так как обработка происходит сразу. Системы коммерческие решают задачу транскрибации на своих серверах, и поэтому, файл для анализа необходимо сначала передать на сервер, что увеличивает общее время обработки.
Процент ошибочно распознанных слов также приблизительно равен для русскоязычной модели. Файлы для распознавания являются не самыми простыми для систем, так как качество записи дикторов имеет помехи и запинки в речи, фрагмент аудиокниги озвучен эмоционально, с ярко выраженными акцентами, перепадами тембра и громкости голоса, музыкальными вставками между актами и главами, ТЕД подкаст имеет вставки английских слов, с которым русскоязычная модель распознавания, очевидно, не справляется.
Таким образом, для дальнейшей работы выбрана библиотека Vosk, из-за количества и гибкости языковых моделей, скорости и точности работы, а также из-за возможности выполнять операции на локальной машине, что положительно сказывается на скорости работы.

3.3.	Реализация модуля транскрибации

Библиотека Vosk предоставляет возможность преобразования речи в текст из заданного аудиофайла [17]. Для распознавания используется класс VoskRecognizer. Создается объект данного класса с использованием объекта класса Model, который представляет собой языковую модель распознавания. Чтобы создать Model, нужно указать путь к папке, в которой находится требуемая модель. В качестве модели можно использовать любую подходящую, в данной работе будут протестированы большая и малая модели русского языка. Как только объект Model инициализирован, можно создавать непосредственно объект VoskRecognizer. Помимо Model, данному объекту необходимо задать частоту дискретизации обрабатываемого аудиофайла. Этот параметр очень важен, так как если его значение будет отличаться от фактической частоты
 
дискретизации аудиофайла, то распознавание будет некачественным [11]. Для объекта VoskRecognizer можно задать параметры, которые отвечают за логгирование работы распознавателя, использования альтернативных расшифровок, использования для работы графического процессора.
После инициализации объекта распознавателя можно приступать непосредственно к транскрибации. Для этого есть несколько вариантов: с использованием буфера типа byte или float. Выбор типа данных буфера влияет на размер обрабатываемого блока аудиофайла и, следовательно, на длительность обработки. Так как, в среднем, аудиофайл с продиктованным классом из 30 человек длится приблизительно от минуты до полутора минут, будет использоваться буфер типа byte. В данный буфер, по мере обработки, будут записываться байты из аудиофайла, которые будут обрабатываться VoskRecognizer. Есть три возможных варианта получения результата: Result, PartialResult и FinalResult. В PartialResult будут отображаться все слова, выписанные отдельно во время обработки текущего блока данных. В Result и FinalResult записываются промежуточные и финальный результат распознавания, включая показатели уверенности. Все результаты обработки записываются в формате JSON, поэтому получающиеся результаты будут конкатенироваться в переменной. Пример полученного объекта изображен на рис.3.1.
 
Рис.3.1. Распознанный элемент

В объекте представлены показатели распознавания, например уверенность распознавания отображается ключом conf. Но больше всего интереса представляет значение ключа word, в который записывается непосредственно распознанное слово.
 
Затем полученная строка отправляется в метод, который разобьет JSON строку на элементы и выделит оттуда только нужные слова, сохранив цельной строкой. Множество таких объектов, которые были распознаны в обрабатываемом фрагменте, находятся в массиве объектов results, который генерируется при каждом переходе на новый фрагмент, то есть формируются и хранятся в Results и FinalResults. Поэтому, чтобы получить транскрибацию всего аудиофайла, необходимо вызывать все PartialResults для формирования данных из каждого распознанного блока, после чего добавить к строке значение FinalResults, в котором и будет храниться весь получившийся текст. Затем парсить получившийся JSON массив и выписывать из ниго значения ключей word.
Весь модуль транскрибации расположен в файле с названием TranscriberService, код которого представлен в П4.1 приложения 4.

3.4.	Методология тестирования модуля

После того, как модуль транскрибации готов к использованию, проводилось тестирование качества его работы в конкретной предметной области. Так как модуль будет интегрирован в сервис по выставлению оценок голосом, обрабатываемые аудиофайлы будут в ограниченном диапазоне длительности, так как, в среднем, классы имеют от 20 до 35 человек. Следовательно, на то, чтобы продиктовать каждого ученика и его оценку, уходит от 30 секунд до 2,5 минут в среднем. Тестироваться будут по очереди компактная модель и полноценная. В каждой модели будут обработаны 15 файлов, в 8 из которых продиктованы 5 учеников, и в 7 из которых было продиктовано 30 учеников. Также, для усложнения задачи и предположения реальной ситуации выставления оценок, в некоторых файлах учеников называют только по фамилии, либо только по имени, либо по фамилии и имени. Будет проверяться количество неправильно распознанных учеников. Учитываться будет только
 
факт правильного или неправильного распознавания, ошибочно распознанная фамилия или имя будут учитываться как неправильно распознанный ученик.
При тестовых замерах время сборки учитываться не будет, так как достаточно один раз собрать проект, чтобы модель создалась и работала на обработке, поэтому считаться будет именно время обработки, то есть время, которое проходит с момента отправки файла на обработку, до момента получения результата.

3.5.	Результаты тестирования

Количество ошибок у моделей в результате тестирования представлены на рис.3.2. Время обработки файлов моделями представлено на рис.3.3. При тестировании сначала обрабатывались 8 файлов с 5 учениками, затем обрабатывались 7 файлов с 30 учениками, этим объясняется значительный скачок в количестве ошибок и времени обработки начиная с 9 файла.
Как можно заметить, время обработки файлов полновесной модели обычно немного больше, однако количество ошибок, как минимум, такое же, как и в легковесной, однако чаще всего ошибок меньше. Для работы в сервисе необходима модель наиболее надежная и стабильная, которая будет в более редких случаях работать с ошибками, поэтому, была выбрана полновесная модель для дальнейшей работы.
 
Рис.3.2. График количества ошибок моделей в файлах
 

 

Рис.3.3. График времени обработки файлов моделями


3.6.	Выводы

В данной главе были произведены реализация и тестирование разработанного модуля преобразования речи в текст с использованием разных моделей. Определена методология тестирования, описаны используемые данные и критерии, по которым проводился дальнейший анализ.
По результатам тестов был сделан выбор используемого в дальнейшей реализации модуля, которым стал полновесный модуль в силу того, что он предоставляет сравнительно лучшие показатели точности распознавания, что является критически важным для дальнейшей работы.

ГЛАВА 4. РЕАЛИЗАЦИЯ ВСПОМОГАТЕЛЬНЫХ МОДУЛЕЙ

В данной главе будет описана реализация вспомогательных модулей, необходимых для более гибкой и корректной работы сервиса.

4.1.	Работа с аудиофайлами. Модуль конвертации

Работа модуля распознавания речи крайне сильно зависит от корректности заданных характеристик обрабатываемого аудиофайла. Можно выделить две
 
основные характеристики, оказывающие наибольшее влияние на качество распознавания: частота дискретизации файла и формат записанного аудио, стерео или моно.
На данном этапе возникает закономерный вопрос – можно ли гарантировать тот факт, что все полученные аудиофайлы будут иметь одинаковые параметры? И будут ли эти параметры приемлемы для обработки, так как для корректной работы необходимо, чтобы аудиофайл был расширения
.wav.
Для решения этой проблемы будет использоваться библиотека NAudio, которая позволяет напрямую в коде работать с аудиофайлами [19]. То есть, будет реализован конвертер аудиофайлов в необходимый формат, на выходе которого должен быть аудиофайл расширения .wav, формата моно и 32кГц частотой дискретизации. Такие настройки являются оптимальными и позволяют достичь наиболее качественного распознавания.
Вначале создается объект WaveFormat, который представлен в библиотеке NAudio, которому задается частота дискретизации в 32000Гц, а также одноканальный режим. Создается объект класса MediaFoundationResampler, которому необходимо в качестве аргументов передать исходный аудиофайл файл и объект класса WaveFormat для настройки характеристик будущего аудиофайла. Теперь, когда все изменения применены, создается новый файл формата .wav, конвертированный из измененного текущего файла. Для этого будет использован метод CreateWaveFile, который служит для создания файлов формата wav и на основе исходного аудиофайла и настроек, хранящихся в объекте класса MediaFoundationResampler, создаст новый аудиофайл с нужными нам параметрами.
Данный функционал реализован в классе MpConverter, который наследуется от абстрактного класса AudioConverter, в котором заданы необходимые значения для конвертации. Исходные коды данных классов представлены в П4.2 и в П4.3 приложения 4 соответственно.
 
4.2.	Обработка распознанного текста

На первом этапе получения текста при его распознавании, все данные записываются единой строкой в переменную. Теперь необходимо разбить полученную строку на массив, отделяя учеников с их отметкой друг от друга. Именно для корректного разделения учеников и однозначного определения, какая отметка ставится конкретному ученику, ставится условие для аудиофайла, чтобы была соблюдена строгая последовательность ученик – оценка.
Поэтому, разбиение строки будет происходить по возможным отметкам в строке, то есть будет разбиваться на массив строк по шаблону “одно или более слов и отметка”. Также, плюсом такого подхода является то, что это позволяет не проговаривать ученика целиком, конечно при условии, что у него нет тезки.
Говоря о возможных отметках, первоначально было принято решение сделать возможным выставление только оценок от 2 до 5. Однако, после посещения учебного заведения и консультации с преподавателями оказалось, что данный подход был неполным. Выяснилось, что электронные журналы поддерживают возможность выставления не только числовых отметок, но и текстовых, таких как “болезнь”, “пропуск”, “зачёт”, “незачёт”, “усвоил”. Каждая такая отметка указывается в журнале своим уникальным набором букв, такими как “Б”, “Н”, “З”, “НЗ” и “У” соответственно. Для обеспечения более широкого функционала и большего удобства пользователям, возможность распознавать текстовые отметки была также добавлена, то есть ученику можно выставить как числовую отметку от 2 до 5, так и текстовую.
Так как транскрибатор записывает распознанные слова прописью, то сначала необходимо перевести все прописные числа в числа, написанные цифрами, а словесные отметки в их уникальный набор букв.
Поэтому, замена в тексте будет происходить для прописных цифр из диапазона от 2 до 5 и для текстовых отметок. Для этого составляется словарь, в котором сопоставляются самые популярные варианты произношения отметок с
 
их числовым эквивалентом, а также указаны отметки и их набор букв. Фрагмент кода с реализацией данного словаря приведен на рис.4.1.
Следовательно, процесс обработки будет следующий: сначала, в полученной строке, заменяются все отметки на их необходимый эквивалент, затем, по этим эквивалентам, разбивается строка на массив подстрок.
 
Рис.4.1. Словарь цифр

Реализация данного модуля представлена в классе TextParser и приведена в П4.4 приложения 4.

4.3.	Работа с текстовыми файлами

Так как на вход разрабатываемому сервису будут подаваться и текстовые файлы, содержащие список учеников класса, необходимо реализовать работу с ними, то есть добавить возможности читать их и создавать результирующий файл. В качестве формата данных файлов было выбрано два самых распространённых типа: JSON и XML.

4.3.1.	Обработчик JSON

Для работы с JSON будет использоваться библиотека Newtonsoft.Json, которая предоставляет возможности работы с JSON структурами [18]. С помощью методов этой библиотеки, реализован метод для чтения JSON файла, который отправляют вместе с аудиофайлом, в котором содержится список учеников, и метод создания результирующего файла, в котором ученикам
 
проставлены отметки. Процесс разбиения JSON структуры на объекты называется десериализацией, то есть преобразование строк в объекты. Например, в полученном файле содержится следующий объект, представленный на рис.4.2.
 
Рис.4.2. JSON объект

На момент получения и чтения файла, данный объект рассматривается как простой набор символов, не отражающий какой-либо сущности. Для того, чтобы преобразовать строки JSON файла в объекты, необходимо провести десериализацию. В библиотеке Newtonsoft.Json есть метод DeserializeObject, который, может разбивать JSON файл на объекты. Для этого ему необходимо задать шаблон объекта, в который должны преобразоваться данные из файла. В данном случае это должны быть объекты класса Pupil, которые репрезентуют необходимую информацию об ученике. Реализация класса Pupil представлена в П4.5 приложения 4. Соответственно, в классе работа будет осуществляться двумя методами: CreateFile для создания результирующего файла и ReadFile для чтения полученного файла. Реализация класса JsonService представлена в П4.6 приложения 4.

4.3.2.	Обработчик XML

XML представляет собой язык разметки, схожий с HTML [25]. Для работы с данным форматом используется пространство имен System.Xml.Linq, которое позволяет сериализовывать и десериализовывать XML документы с использованием LINQ синтаксиса. Основным объектом, с которых работает данная технология, является XElement, который отражает объект XML и на основе которого строится структура документа. Реализация данного
 
обработчика приведена в П4.7 приложения 4. Пример содержимого XML документа приведен на рис.4.3.
 
Рис.4.3. Пример XML документа


4.4.	Модуль сопоставления

Итак, после конвертации аудиофайла, его транскрибации и обработки, а также чтения файла с учениками, в программе хранится 2 комплекта данных: ученики с их оценками, которые были получены из аудиофайла, и список учеников, который был получен из текстового файла. Следующим этапом необходимо произвести сопоставление полученных данных из аудиофайла с фактическими данными из списка учеников. При реализации модуля сопоставления будет использоваться алгоритм Джаро-Винклера, описанный в параграфе 1.3.
Чтобы найти самую похожую строку, то есть найти фактические ФИО распознанного ученика, будет происходить итеррирование по всему списку учеников, полученному из текстового файла. Берется имя, фамилия и имя с фамилией текущего ученика из списка и сравнивается с распознанным из аудиофайла учеником. Для каждой такой пары находится минимальное расстояние, после чего находится минимальное среди найденных расстояний, и именно оно будет сохранено для дальнейшего сравнения вместе с позицией в списке. Набор из 3 расстояний необходим потому, что при неудачном распознавании может получиться меньшее расстояние, если учитывать только одну из частей ФИО или наоборот, учитывать полностью.
Так будет происходить по всему списку учеников, пока не обработаются все распознанные значения. После сравнения текущего распознанного элемента
 
со всеми учениками из списка, по позиции с минимальным расстоянием определяется отметка ученика. Реализованный класс Correlation представлен в П4.9 приложения 4.

4.5.	Выводы

В данной главе была описана разработка модуля системы распознавания речи и преобразования ее в текст. Также разработан модуль сопоставления, который предназначен для того, чтобы распознанные строки сопоставлять с оригинальным списком учеников, полученным из файла. Необходим данный модуль для коррекции неправильно распознанных учеников и правильного выставления оценок нужным ученикам.

ГЛАВА 5. РАЗРАБОТКА WEB API

В рамках данной главы разработанные модули будут объединены в единый WEB API, чтобы пользователь мог делать запросы к сервису и получать в ответ результирующий файл. Реализация будет с использованием языка C# и технологии ASP.NET Core, которая является частью платформы .Net. Также в данной главе будет описана интеграция в проект ознакомительного интерфейса и документации с использованием Swagger.

5.1.	Разработка API

В данном пункте будет описан процесс создания Web API на языке программирования C#, используя платформу для разработки веб-приложений ASP.NET Core, включая объединение ранее разработанных модулей в единую систему. Разработка проекта будет происходит в IDE Rider, которая предоставляет возможность создания проекта по шаблону Web API с использованием ASP.NET Core. Схема выполнения обработки
 
пользовательского	запроса	сервисом	представлена	на	рис.5.1.	Диаграмма классов проекта представлена на рис.П2.1 приложения 2.
 
Рис.5.1. Схема обработки запроса

Элементы данной схемы описаны в последующих пунктах работы.

5.1.1.	Точка входа в программу

При запуске программы работа начинаться со считывания файла Program.cs, который является точкой входа и в котором происходит вся настроечная инициализация объектов и запуск сервера.
Основная часть создания всех необходимых сущностей, таких как WebApplicationBuilder и WebApplication, настройка работы сервисов, адресация маршрутов и настройка контроллеров происходит в файле Program.cs. Код данного файла приведен в П4.10 приложения 4.
Создание приложения на ASP.NET Core начинается с создания объекта класса WebApplicationBuilder [13]. Данный объект необходим для создания главного элемента проекта, объекта WebApplication, однако, через него также можно настраивать поведение приложения, его параметры и характеристики. Например, в коде, через параметр Services, у WebApplicationBuilder добавляются дополнительные сервисы для контроллеров, добавление настройщика по созданию и регистрации конечных точек, поддерживающий концепцию минимальных API, а также использование Swagger UI.
После настройки WebApplicationBuilder, на его основе, с помощью команды build, создается WebApplication – непосредственно приложение. С ним
 
также происходят манипуляции по настройке, которые указываются для корректной работы элементов из WebApplicationBuilder и более тонкой настройки отдельных элементов программы.

5.1.2.	Контроллер

Обязательной частью любого Web API является контроллер. Контроллер необходим для того, чтобы обрабатывать входящий HTTP запрос и отправлять ответ. Для работы необходимо иметь хотя бы один контроллер.
Контроллер приложения реализован в файле APIController.cs, код которого приведен в П4.11 приложения 4.
Для создания контроллера необходим класс, который будет наследоваться от класса ControllerBase, который является базовым классом для контроллеров в ASP.NET Core. Также, для класса FileUploadController, указаны атрибуты, а именно APIController, который явно указывает, что данный класс является контроллером API, а также Route, который задает маршрут для достижения данного контроллера при запросе.
Для самого метода обработки запроса указывается атрибут HttpPost, который указывает, что метод будет обрабатывать POST запросы пользователя. Как параметр атрибута указывается путь для достижения данного конкретного метода для пользователя. Для обращения к сервису пользователю необходимо отправить запрос по адресу “…/api/upload”.
Обработчик принимает от пользователя 2 файла: аудиофайл с продиктованными учениками и их отметками, а также файл со списком учеников. Аудиофайл должен быть формата MP3, WAV или M4A, а список учеников должен быть формата JSON или XML. Данные файлы скачиваются на сервер и отправляются в сервис по обработке данных файлов. После обработки и создания результирующего файла, который ответом отправляется пользователю для скачивания.
 
5.1.3.	Сервисы

Для обработки запросов необходимо реализовать сервис обработки, а также необходимы сервисы по конвертации аудиофайлов и привидению их в нужный формат, и сервис по работе с файлами формата JSON и XML. Большая часть этого уже реализована и описана в главе 3, остается только интегрировать это в сервис и сделать сервис по обработке пользовательских запросов.
Для формирования результирующего файла необходимо обработать полученные файлы. Так как обращений к серверу может быть больше одного за момент времени, сервис по обработке таких обращений необходимо настроить правильно. Поэтому, как показано в П4.10 приложения 4, сервис обработки ProcessingService добавляется с опцией transient, что означает, что экземпляр данного сервиса будет создаваться отдельный на каждый вызов. Такой подход необходим, так как пользователи отправляют разные файлы, которые не должны смешиваться или обрабатываться с файлом, который был отправлен не с ним. Код реализации класса ProcessingService представлен в П4.12 приложения 4.
При вызове сервиса в нем, сначала, определяются полученные файлы, их формат и расширение. Нужно это для корректной обработки, а определение типа файла со списком учеников, также, определяет и формат результирующего файла. Затем происходит конвертация аудиофайла к необходимому формату, после чего читается список учеников. Следующим этапом происходит транскрибация аудиофайла, парсинг полученных результатов и составление списка полученных данных. После этого делается сопоставление распознанных данных и фактического списка учеников, выставляются отметки распознанным ученикам. Полученный список конвертируется в JSON файл и отправляется ответом.
Также, с опцией singleton, в качестве сервиса вынесен и функционал транскрибации, так как возможных инициализированных моделей может быть только одна в силу того, что она хранится физически в проекте и не может
 
одновременно читаться и записываться несколькими потоками, такое поведение приведет к ошибке.
Работа с файлами также вынесена в раздел сервисов, но работает локально в каждом запросе. Так как оба варианта обработчика файлов выполняют одинаковые, по своей сути, действия, они реализуют интерфейс IFileService, который обязует их реализовать два метода: ReadFile и CreateFile.

5.1.4.	Модели

В качестве моделей в данном проекте выступают две основные сущности: ученик и модель, которая используется в транскрибации.
Модель ученика отражает необходимую информацию, такую как ФИО и отметка. Модель для распознавания же нужна для того, чтобы оптимизировать и настроить работу модуля распознавания. Так как модель хранится физически в отдельной папке, при ее инициализации в проекте происходят процессы чтения и записи физических файлов, из-за этого возникает ситуация, в которой нет возможности инициализировать больше 1 модели, так как иначе возникают ошибки чтения занятой области памяти. Выходом из данной ситуации является реализация паттерна singleton, который контролирует, чтобы объект существовал в единственном экземпляре. В языке C# можно явно реализовать паттерн с помощью проверок существования экземпляра объекта, однако более быстрым способом является использование lazy инициализации [14]. Она автоматически контролирует единственность экземпляра объекта в программе и оптимизирует расходы системы, давая доступ к объекту только тогда, как он необходим. Код реализации класса TranscriberModel представлен в листинге в П4.13 приложения 4.
 
5.2.	Добавление Swagger в проект

Первоначально, для ознакомительного интерфейса к документации, предполагалась реализация отдельной веб-страницы, макет которой бы создавался в Figma, а затем использовался в проекте. Однако, данный вариант не является наилучшим, так как для создания виртуальной документации API, на сегодняшний день, самым популярным и общепринятым вариантом является Swagger. Этой технологией пользуются и крупные компании, например PayPal, Boeing, Google, Ebay и многие другие.
Возможность использования данной технологии в ASP.NET Core реализуется с помощью добавления соответствующего сервиса в проект, с помощью команды AddSwaggerGen [8]. Далее происходит первичная настройка, задается информация для отображения и версия. Данная информация будет отображаться на главном экране документации.
Для того, чтобы использовать Swagger, необходимо также включить его в уже созданном экземпляре WebApplication, используя команды UseSwagger и UseSwaggerUI. Последняя команда и позволяет сгенерировать полноценную HTML страницу с документацией, на вход ей подается JSON файл с описанием структуры API.
Также происходит и добавление генерируемого XML файла, в котором будет находиться описание конечной точки, на которую необходимо отправлять запрос. Это описание является не обязательным, однако его рекомендуется включать в проект, чтобы улучшить качество документации и внести ясность в возможности использования API. Пример такой дополнительной документации приведен на рис.5.2.
В данном случае задаются секции общего описания, находящиеся в разделе
<summary>, которые описывают конечную точку, чтобы пользователю был понятен общий функционал.
 

 
Рис.5.2. Формирование документации для Swagger

Затем, в секции <remarks>, прописывается более подробная информация, например то, какие файлы необходимо отправить в запросе, примеры этих файлов, ограничения и рекомендации. В секции <response> прописывается информация о возможных ответах от API.
Также для использования Swagger вместе со стартом приложения, в файле со стартовыми настройками проекта добавляется профиль, в котором задается стартовая страница как Swagger. Код настроенного профиля приведен на рис.5.3.
 
Рис.5.3. Профиль для работы со Swagger

С настроенным профилем при запуске проекта на устройстве автоматически откроется браузер по адресу, где разворачивается сервер и где находится главная страница Swagger UI. Стартовая страница, открывающаяся в данном проекте, приведена на рис.5.4.
 

 
Рис.5.4. Профиль для работы со Swagger

Как можно заметить, все дополнительные настройки успешно применились, что позволило явно показать пользователю форматирование и ожидаемое содержание отправляемых текстовых файлов, а также обозначить ограничения на типы ожидаемых файлов.
Снизу справа есть кнопка “Try it out”, которая позволяет прямо на этой же странице попробовать отправить запрос на выбранную конечную точку. Интерфейс для апробации функционала представлен на рис.5.5.
Отображается 2 поля для загрузки в них необходимых файлов, для отправки запроса достаточно нажать на кнопку Execute. Как только запрос обработан и на него получен ответ, отображается информация о запросе и полученном ответе. Пример отображения ответа показан на рис.5.6.
 
Рис.5.5. Предлагаемый интерфейс взаимодействия с API
 

 

Рис.5.6. Отображение полученного ответа

Swagger показывает, какой был отправлен запрос и на какой адрес. После этого отображается ответ, в теле которого находится файл с результатами, который предлагается скачать, а также описание HTTP кода ответа. В самом низу располагается список статусных кодов HTTP и описание того, что они означают в контексте работы с API. Это также настраивается в секции <response> дополнительного описания.

5.3.	Выводы

В данной главе была описана разработка сервиса получения информации об успеваемости учащихся с использованием системы распознавания речи. Данный сервис реализован с использованием архитектуры REST API, с интеграцией спецификации OpenAPI и интеграцией Swagger UI для визуализации документации.
Также была описана спецификация OpenAPI, которая используется Swagger для генерации виртуальной документации. Описана работа со Swagger на языке C# с использованием платформы ASP.NET, затронуты важные моменты настройки отображения, настройки дополнительного описания работы с конечными точками, описания API.
 
ГЛАВА 6. ТЕСТИРОВАНИЕ СЕРВИСА

В данной главе будет описана методология тестирования сервиса, данные для обработки, проанализированы полученные результаты.

6.1.	Методология тестирования

После того, как сервис был разработан, его необходимо запустить и протестировать. Разворачиваться сервер для тестирования будет в локальной сети. Тестироваться будет время, которое проходит с момента отправки файлов на обработку, то есть отправки запроса пользователя, до момента отправки пользователю в ответ результирующего файла. Это время является критически важным для системы, так как это и будет фактическим временем общения пользователя с сервером, соответственно данный интервал и будет являться определяющим в вопросе удобства использования.
Непосредственно о файлах для тестирования. Были заранее подготовлены 4 текстовых документа, в которых было сгенерировано от 25 до 30 фамилий, имен и отчеств учеников, которым были проставлены отметки. В качестве отметок выступает стандартный набор таковых в электронном журнале, которые были описаны в пункте 4.2.

6.2.	Тестирование

Чтобы приблизить тестирование к реальным условиям и получить репрезентативный результат, озвучивать данные списки учеников было доверено школьным учителям непосредственно в школе. Соответственно, записанные файлы приближены к фактической потенциальной среде использования, при этом продиктованы людьми, для которых озвучивание оценок является рутинным, ежедневным процессом, что делает их способ диктовки по-своему уникальным, что положительно влияет на качество полученных при тестировании результатов. Пять учителей записали файлы с
 
предложенными 4 классами, что дает для тестирования 20 наборов файлов. Каждый набор будет отправлен в качестве запроса сервису и будет замерено время от отправки до получения ответа. Аудиофайлы названы относительно учителя и номера списка учеников, например У_1_1 – это файл, записанный первым учителем с информацией из первого списка учеников. Результаты тестирования представлены в табл.П3.1 приложения 3.
По результатам проведенного тестирования можно сделать вывод о том, что среднее время обработки запроса приблизительно равно 8,11 секунд. На диктовку оценок для классов, состоящих от 25 до 30 человек, в среднем, уходило
55 секунд. Так как файлы записывались непосредственно в школе, в них присутствуют фоновые шумы, что увеличивает репрезентативность получаемых результатов. Также необходимо описать и общие результаты касательно точности распознавания и полученных файлов. Все 20 файлов имели правильные результаты выставления отметок всем ученикам. Суммарное время работы, с учетом записывания аудиофайла учителем, формирования и отправки запроса составляет в среднем 73,11 секунд.
Также был проведен опрос среди 50 преподавателей о данном проекте, считают ли они его удобным, хотели бы им пользоваться или нет. Результаты опроса представлены на рис.6.1. По результатам, большинство учителей положительно оценили проект и выразили в нем заинтересованность. Среди положительных моментов отмечали возможность сократить время на выставлении оценок, отдых для глаз, так как не придется высматривать нужного ученика и оценку ему. Как таковых отзывов против высказано не было, однако некоторые респонденты выражали нежелание или сомнения в перспективе пользования подобным сервисом, так как негативно относятся к технологии распознавания речи в целом.
 

 
Рис.6.1. Диаграмма результатов опроса учителей

6.3.	Сравнительный анализ с аналогичными решениями.

Ближайшими конкурентами данному сервису являются сторонние API, которые также позволяют пользователям транскрибировать их аудиофайлы и возвращают полученный в результате текст. Среди таковых можно выделить сервисы, описанные в параграфе 1.2 данной работы, такие как Yandex Speech Kit, Google Cloud Stt и Azure Stt. По структуре работы разработанный сервис схож с возможностями перечисленных сервисов, так как с каждым из представленных можно работать в формате Web API, отправляя на обработку аудиофайлы.
Основополагающим критерием сравнения является время взаимодействия с сервисом, то есть время с момента отправки запроса на обработку до момента получения ответа пользователем. Для системы, которая будет интегрировать возможности сервиса, наиболее важным является именно данный временной интервал, так как только после получения ответа становится возможным дальнейшая работа.
Также будет сравниваться и качество распознавания. При этом, неправильно распознанное имя или фамилия будут считаться как неправильно распознанный ученик и учитываться как ошибка. Также за ошибку распознавания будет считаться некорректно распознанная отметка ученика.
 
Для сравнения будут взяты 5 файлов из тех, которые были записаны учителями. Сначала, из-за ограничения пробных версий, были отобраны только аудиофайлы, длительность которых не превышает одной минуты. Затем, среди этих файлов были отобраны те, что имеют наибольшую длительность, и среди них отобрали те, на которых разработанный сервис имел наибольшее время обработки.
Результаты проведенного сравнения представлены в табл.П3.2 приложения 3. Исходя из данных таблицы можно утверждать, что все сравниваемые сервисы выполняют обработку запросов в приблизительно одинаковом временном интервале. Однако, стоит также учитывать тот факт, что все проведенное распознавание разработанным сервисом было правильным, благодаря прохождению этапов обработки и сопоставления. При этом, замеры времени проходили по одинаковому критерию для всех, то есть за прошедший промежуток времени сервис не только транскрибировал аудиофайл, но и прочитал текстовый файл с учениками, обработал полученный результат транскрибации, провел сопоставление распознанных учеников, выставил им соответствующие отметки, после чего сформировал на основании сгенерированных данных новый файл и отправил его ответом пользователю. В то же время аналогичные сервисы не предоставляют подобного функционала, и за указанное время произвели только транскрибацию и вернули полученный в результате текст в качестве ответа на запрос. Данный способ взаимодействия также имеет место быть, однако в таком случае, отправителю придется взять на себя работу по сопоставлению данных и формированию итогового файла, в то время как разработанный сервис делает это сразу же, во время обработки и возвращает уже готовый для дальнейшей интеграции и работы текстовый файл в нужном формате.
 
6.4.	Выводы

В данной главе было произведено тестирование разработанного сервиса, по полученным результатам определено среднее время обработки, а также среднее время, которое тратится на взаимодействие с сервисом на данном этапе. Помимо этого, было проведено сравнение с ближайшими аналогами, которыми выступили сервисы распознавания речи, рассмотренные в параграфе
1.2.
 
ЗАКЛЮЧЕНИЕ

В результате выполнения данной работы поставленная цель была достигнута: был разработан и протестирован сервис получения информации об успеваемости учащихся с использованием системы распознавания.
Для достижения данной цели были решены следующие задачи:
–	проведен обзор существующих систем распознавания речи
–	проведено тестирование систем и выбрана система для дальнейшей работы
–	реализован и протестирован модуль транскрибации;
–	реализованы модули сопоставления, обработки текста, конвертации аудиофайлов, работы с файлами формата JSON и XML;
–	реализован web API с интеграцией в него всех разработанных модулей;
–	выполнена интеграция и настроена документация для API;
–	проведено	тестирование	разработанного	сервиса,	собраны	отзывы потенциальных пользователей.
Для ускорения обработки запросов можно использовать более мощное оборудование, так как рекомендацией к полновесной модели распознавания, используемой в программе, является использование сервера с графическими процессорами и большим количеством оперативной памяти.
В дальнейшем, работу с разработанным сервисом можно интегрировать в системы электронного оценивания, например школьные электронные журналы. Также, для защиты пользовательских данных, можно реализовать шифрование пакетов при передаче для обеспечения конфиденциальности.
 
СПИСОК СОКРАЩЕНИЙ И УСЛОВНЫХ ОБОЗНАЧЕНИЙ

API	Application Programming Interface
HTML	Hypertext Markup Language
IDE	Integrated Development Environment
IT	Information Technology
REST	Representational State Transfer
STT	Speech-To-Text
SDK	Software Development Kit
UI	User Interface
WER	Word Error Rate
ФИО	Фамилия Имя Отчество
ИИ	Искусственный интеллект
 
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ

1.	Анатольевич К. А., Сергеевна К. И. Методология оценивания работы систем автоматического распознавания речи // Известия высших учебных заведений. Приборостроение. 2012. № 11 (55). C. 38–43.
2.	Андреевна С. Д., Николаевич К. О., Викторович С. А. Построение и обучение нейронной сети для решения задачи распознавания речи // Труды НГТУ им. Р. Е. Алексеева. 2015. № 3 (110). C. 77–84.
3.	Бясова Д. Р., Немцова В. А. Алгоритм автоматизации подбора соответствий номенклатуры фармацевтических организаций // Молодые ученые в решении актуальных проблем науки. Владикавказ, 12–14 декабря 2019 года, 2019.C. 24–26.
4.	Введение в web APIs - Изучение веб-разработки | MDN [Электронный ресурс]. URL: https://developer.mozilla.org/ru/docs/Learn/JavaScript/Client- side_web_APIs/Introduction (дата обращения: 06.05.2022).
5.	Владимирович А. И., Александрович М. М. Современные методы распознавания речи для построения голосового интерфейса управления системами специального назначения // Известия высших учебных заведений. Поволжский регион. Технические науки. 2019. № 2 (50). C. 3–10.
6.	Казанферович А. А. Параметры и классификация систем распознавания речи // Модели, системы, сети в экономике, технике, природе и обществе. 2014.
№ 1 (9). C. 79–84.
7.	Н.В Гаврилович., С.Н Сейтвелиева. Анализ коммерческих систем распознавания речи с открытым API // Таврический научный обозреватель. 2016. № 6 (11). C. 201–205.
8.	Начало работы с Swashbuckle и ASP.NET Core [Электронный ресурс]. URL: https://docs.microsoft.com/ru-ru/aspnet/core/tutorials/getting-started-with- swashbuckle (дата обращения: 14.05.2022).
9.	Фролов А. В., Фролов Г. В. Cинтез и распознавание речи. Современные решения. / А. В. Фролов, Г. В. Фролов, 2003.
 
10.	Фонема — Википедия [Электронный ресурс]. URL: https://ru.wikipedia.org/wiki/Фонема (дата обращения: 19.02.2022).
11.	Частота дискретизации — Википедия [Электронный ресурс]. URL: https://ru.wikipedia.org/wiki/Частота_дискретизации (дата обращения: 22.02.2022)
12.	Что такое REST API — RESTful веб-сервисы / Хабр [Электронный ресурс]. URL: https://habr.com/ru/post/483202/ (дата обращения: 08.05.2022).
13.	ASP.NET Core и C# | Введение [Электронный ресурс]. URL: https://metanit.com/sharp/aspnet6/1.1.php (дата обращения: 07.05.2022).
14.	C# и .NET | Отложенная инициализация и тип Lazy [Электронный ресурс]. URL: https://metanit.com/sharp/tutorial/20.1.php (дата обращения: 13.05.2022).
15.	Comparison of the Java and .NET platforms - Wikipedia [Электронный ресурс]. URL: https://en.wikipedia.org/wiki/Comparison_of_the_Java_and_.NET_platforms (дата обращения: 25.05.2022).
16.	Ghahramani Z. An introduction to hidden markov models and bayesian networks // International Journal of Pattern Recognition and Artificial Intelligence. 2011.
17.	GitHub - alphacep/vosk-API: Offline speech recognition API for Android, iOS, Raspberry Pi and servers with Python, Java, C# and Node // GitHub [Электронный ресурс]. URL: https://github.com/alphacep/vosk-API (дата обращения: 20.03.2022).
18.	GitHub - JamesNK/Newtonsoft.Json: Json.NET is a popular high- performance JSON framework for .NET [Электронный ресурс]. URL: https://github.com/JamesNK/Newtonsoft.Json (дата обращения: 14.04.2022).
19.	GitHub - naudio/NAudio: Audio and MIDI library for .NET // GitHub [Электронный ресурс]. URL: https://github.com/naudio/NAudio (дата обращения: 05.04.2022).
 
20.	Huang X., Acero A., Hon H.-W. Spoken Language Processing: A Guide to Theory, Algorithm, and System Development 2001.
21.	Kaldi: Kaldi [Электронный ресурс]. URL: http://kaldi-asr.org/doc/ (дата обращения: 08.02.2022).
22.	OpenAPI // OpenAPI Initiative [Электронный ресурс]. URL: https://www.openAPIs.org/ (дата обращения: 15.05.2022).
23.	VOSK Offline Speech Recognition API // VOSK Offline Speech Recognition API [Электронный ресурс]. URL: https://alphacephei.com/vosk/ (дата обращения: 12.02.2022).
24.	What is Swagger [Электронный ресурс]. URL: https://swagger.io/docs/specification/2-0/what-is-swagger/ (дата обращения: 15.05.2022
25.	XML Введение - XML: Extensible Markup Language | MDN [Электронный ресурс]. URL: https://developer.mozilla.org/ru/docs/Web/XML/XML_introduction (дата обращения: 11.05.2022).
 
Приложение 1.
Таблицы результатов тестирования систем распознавания речи

Таблица П1.1
Результаты тестирования Vosk API

Файл	Время обработки, сек	WER, %
Книга_1	2,98	21,55
Книга_2	3,09	22,06
Книга_3	2,62	29,28
Книга_4	2,98	16,87
Книга_5	3,00	26,84
Тед_1	3,01	13,81
Тед_2	3,13	25,38
Тед_3	3,27	19,31
Тед_4	3,23	21,61
Тед_5	3,36	20,83
Диктор_1	2,99	20,46
Диктор_2	2,99	22,58

Таблица П1.2
Результаты тестирования Kaldi

Файл	Время обработки, сек	WER, %
Книга_1	3,12	20,23
Книга_2	3,56	21,89
Книга_3	2,89	30,12
Книга_4	3,02	15,01
Книга_5	2,98	24,91
Тед_1	2,99	14,06
Тед_2	3,01	26,16
Тед_3	3,43	19,68
Тед_4	4,10	22,41
Тед_5	3,76	20,98
Диктор_1	3,01	19,57
Диктор_2	3,03	21,38
 
Таблица П1.3
Результаты тестирования Yandex Speech Kit

Файл	Время обработки, сек	WER, %
Книга_1	9,48	19,35
Книга_2	7,74	23,39
Книга_3	4,80	36,73
Книга_4	5,87	20,48
Книга_5	5,88	16,41
Тед_1	4,70	14,15
Тед_2	5,77	16,26
Тед_3	9,34	14,11
Тед_4	5,97	19,92
Тед_5	8,18	21,82
Диктор_1	8,21	24,79
Диктор_2	7,25	23,52

Таблица П1.4
Результаты тестирования Google Cloud Stt

Файл	Время обработки, сек	WER, %
Книга_1	11,32	22,87
Книга_2	10,42	19,70
Книга_3	9,12	39,47
Книга_4	7,47	24,66
Книга_5	4,56	20,39
Тед_1	4,89	18,09
Тед_2	9,56	19,69
Тед_3	12,49	24,34
Тед_4	7,89	19,33
Тед_5	6,91	20,57
Диктор_1	15,93	24,45
Диктор_2	7,25	21,35
 
Таблица П1.5
Результаты тестирования Azure Stt

Файл	Время обработки, сек	WER, %
Книга_1	14,54	22,14
Книга_2	13,66	10,25
Книга_3	5,13	35,89
Книга_4	13,40	28,54
Книга_5	12,37	21,50
Тед_1	18,04	15,09
Тед_2	13,19	25,38
Тед_3	13,20	22,36
Тед_4	13,06	18,25
Тед_5	13,42	24,19
Диктор_1	8,14	26,32
Диктор_2	9,25	23,33

Таблица П1.6
Характеристики систем распознавания



Система	
Среднее время обработки, сек	
Средний WER,
%	
Алгоритм извлечения признаков	
Поддерживаем ые языки


Vosk API	

3,03	

21,85	

MFCC, PLP	Русский, английский, множество моделей других языков


Kaldi	

3,24	

21,36	

MFCC, PLP	Русский, английский, множество моделей других языков

Yandex Speech Kit	

10,26	

20,91	

-	Русский, английский, многие другие языки
 
Продолжение табл.П1.6


Google Cloud Stt	

12,15	

22,90	

-	Русский, английский, также многие
языков


Azure Stt	

12,28	

21,93	

-	Русский, английский, множество
других языков
 
Приложение 2.
Диаграмма классов проекта

Рис.П2.1. Диаграмма классов проекта
 
Приложение 3.

Результаты тестирования сервиса


Таблица П3.1
Результаты тестирования скорости работы сервиса


Файл	Длительность файла, сек	Время обработки, сек
У_1_1	51	8,15
У_1_2	47	8,23
У_1_3	54	8,86
У_1_4	44	7,25
У_2_1	48	7,60
У_2_2	52	8,61
У_2_3	58	8,97
У_2_4	64	7,79
У_3_1	48	8,22
У_3_2	55	8,32
У_3_3	62	7,76
У_3_4	64	8,90
У_4_1	49	8,20
У_4_2	73	7,31
У_4_3	57	8,54
У_4_4	66	7,97
У_5_1	48	7,08
У_5_2	57	7,44
У_5_3	54	8,77
У_5_4	49	8,28
 
Таблица П3.2
Результаты сравнения сервиса с аналогами


Файл	Система
распознавания	Время обработки, сек	Количество
ошибок
У_1_3	VoiceGradeAPI	8,56	0
У_1_3	Yandex Speech Kit	9,31	4
У_1_3	Google Cloud Stt	9,12	2
У_1_3	Azure Stt	11,42	1
У_2_3	VoiceGradeAPI	8,96	0
У_2_3	Yandex Speech Kit	8,58	5
У_2_3	Google Cloud Stt	9,56	6
У_2_3	Azure Stt	12,06	3
У_3_2	VoiceGradeAPI	8,12	0
У_3_2	Yandex Speech Kit	8,32	7
У_3_2	Google Cloud Stt	7,25	4
У_3_2	Azure Stt	11,66	4
У_4_3	VoiceGradeAPI	8,54	0
У_4_3	Yandex Speech Kit	9,12	3
У_4_3	Google Cloud Stt	7,89	5
У_4_3	Azure Stt	12,2	2
У_5_2	VoiceGradeAPI	7,96	0
У_5_2	Yandex Speech Kit	7,74	6
У_5_2	Google Cloud Stt	6,91	3
У_5_2	Azure Stt	9,23	2
 
Приложение 4.
Исходные коды разработанных классов


П4.1. Исходный код класса TranscriberService

public class TranscriberService
{
private static VoskRecognizer _recognizer;
private static readonly object SyncLocker = new (); public TranscriberService()
{
var model = TranscriberModel.Instance;
_recognizer = new VoskRecognizer(model.Model, 32000.0f); Initialize(_recognizer);
}

//Initialize parameters of recognizer
private static void Initialize(VoskRecognizer rec)
{
Vosk.Vosk.SetLogLevel(-1); rec.SetMaxAlternatives(0); rec.SetWords(true);
}

private static String GetTranscribedText(string finalResult)
{
var currentElement = new StringBuilder();
//Parse JSON string to elements
var parsedResult = JArray.Parse(finalResult);

foreach (var results in parsedResult)
{
for (var i = 0; i < results["result"].Count(); i++)
{
//Get needed element in JSON object and add it in string currentElement.Append(results["result"]?[i]?["word"]); currentElement.Append(' ');
}
}

return currentElement.ToString();
}


public string TranscribeAudio(string audioFilePath)
{
var transcribedText = new StringBuilder("[");
 

//Transcribe audiofile and add results to StringBuilder using Stream source = File.OpenRead($@"{audioFilePath}"); var buffer = new byte[4096];
int bytesRead; lock (SyncLocker)
{
while ((bytesRead = source.Read(buffer, 0, buffer.Length)) > 0)
{
if (!_recognizer.AcceptWaveform(buffer, bytesRead))
{
_recognizer.PartialResult();
}
}

transcribedText.Append(_recognizer.FinalResult() + ']');
//Reset recognizer for other session
_recognizer.Reset();
}
//get and return parsed from JSON text
return GetTranscribedText(transcribedText.ToString());
}
}

П4.2. Исходный код класса MpConverter

public sealed class MpConverter : AudioConverter
{
public MpConverter(string filePath) : base(filePath)
{
}

public override string ConvertAudio()
{
 
try
{




outFormat);

}
 


using var waveFileReader = new AudioFileReader(Infile); var outFormat = new WaveFormat(NeededRate, 1);
using var resample = new MediaFoundationResampler(waveFileReader, WaveFileWriter.CreateWaveFile(Outfile, resample);
 
catch (Exception e)
{
throw new Exception("Error with audio file, try another one");
}

return Outfile;
 
}
}

П4.3. Исходный код класса AudioConverter

public abstract class AudioConverter
{
private protected readonly string Infile; private protected readonly string Outfile; private protected const int NeededRate = 32000;

protected AudioConverter(string filePath)
{
this.Infile = filePath;
this.Outfile = Infile.Substring(0, Infile.LastIndexOf(("\\"), StringComparison.Ordinal)) +
@"\converted.wav";
}

public abstract string ConvertAudio();
}

П4.4. Исходный код класса TextParser

public class TextParser
{
public List<string> ParseData(string allData)
{
allData = ConvertToNumbers(allData.ToLower());
var separatedElements = allData.Trim().Split("\n").Where(x => x.Trim().Length != 1).ToList();
return separatedElements;
}

private static string ConvertToNumbers(string originalString)
{
//Dictionary to convert words to notes
var noteTable = new Dictionary<string, string>
{

{ "два", "2" }, { "двойка", "2" }, { "неудовлетворительно", "2" },
{ "три", "3" }, { "тройка", "3" }, { "удовлетворительно", "3" },
{ "четыре", "4" }, { "четверка", "4" }, { "хорошо", "4" },
{ "пять", "5" }, { "пятерка", "5" }, { "отлично", "5" },
{ "пропуск", "Н" }, { "болезнь", "Б" }, { "зачёт", "З" }, { "незачёт", "НЗ" }, { "усвоил", "У" }};
//Replace words with numbers and separate pupils with newline symbol
 
foreach (var pair in noteTable)
{
var rgx = new Regex(@$"\s+{pair.Key}");
originalString = rgx.Replace(originalString, " " + pair.Value + "\n");
}

return originalString.ToUpper();
}
}

П4.5. Исходный код класса Pupil


public class Pupil
{
public string Surname { get; } public string Name { get; }
public string? MiddleName { get; } public string? Note { get; set; }
public Pupil(string name, string surname, string? middleName)
{
Name = name; Surname = surname;
MiddleName = middleName;
}
}

П4.6. Исходный код класса JsonService

public sealed class JsonService : IFileService
{
private readonly string _generatedFilesDirectory = Directory.GetCurrentDirectory() + @"\GeneratedFiles";
public string CreateFile(List<Pupil> pupils)
{
if (!Directory.Exists(_generatedFilesDirectory)) Directory.CreateDirectory(_generatedFilesDirectory);
var jsonFilePath = _generatedFilesDirectory + @$"\{Guid.NewGuid()}.json"; TextWriter writer = null;
try
{
var json = JsonConvert.SerializeObject(pupils, Formatting.Indented); writer = new StreamWriter(jsonFilePath);
writer.Write(json);
 
return jsonFilePath;
}
finally
{
if (writer is not null) writer.Close();
}
}

public List<Pupil> ReadFile(string path)
{
TextReader reader = null; try
{
reader = new StreamReader(path); var read = reader.ReadToEnd();
var jsonPersons = JsonConvert.DeserializeObject<List<Pupil>>(read);

return jsonPersons ?? throw new Exception("Invalid JSON file");
}
finally
{
if (reader is not null) reader.Close();
}
}
}

П4.7. Исходный код класса XmlService

public sealed class XmlService : IFileService
{
private readonly string _generatedFilesDirectory = Directory.GetCurrentDirectory() + @"\GeneratedFiles";

public string CreateFile(List<Pupil> pupils)
{
if (!Directory.Exists(_generatedFilesDirectory)) Directory.CreateDirectory(_generatedFilesDirectory);
var xmlFilePath = _generatedFilesDirectory + @$"\{Guid.NewGuid()}.xml"; TextWriter writer = null;
try
{
var xmlText = new XElement("PupilsList", from pupil in pupils
select new XElement("Pupil",
new XElement("Name", pupil.Name),
new XElement("Surname", pupil.Surname),
new XElement("Patronymic", pupil.MiddleName), new XElement("Note", pupil.Note))
 
);
var stringXml = xmlText.ToString(); writer = new StreamWriter(xmlFilePath); writer.Write(stringXml);
return xmlFilePath;
}
finally
{
writer?.Close();
}
}

public List<Pupil> ReadFile(string path)
{
TextReader reader = null; try
{
reader = new StreamReader(path); var readXml = reader.ReadToEnd();
var xmlElements = XElement.Parse(readXml);
var parsedElements = (from el in xmlElements.Elements("pupil") select new Pupil(el.Attribute("Name").Value,
el.Attribute("Surname").Value,
el.Attribute("Patronymic").Value)).ToList(); return parsedElements;
}
finally
{
reader?.Close();
}
}
}

П4.8. Исходный код класса JaroWinklerDistance

public static class JaroWinklerDistance
{
private const double DefaultMatches = 0.0;

public static double GetDistance(string? firstWord, string? secondWord)
{
if (firstWord == null || secondWord == null) return DefaultMatches; var jaroDistance = JaroDistance(firstWord, secondWord);
var prefixLength = PrefixLength(firstWord, secondWord);
return jaroDistance + prefixLength * 0.1 * (1.0 - jaroDistance);
}

private static int PrefixLength(string? firstWord, string? secondWord)
 
{
const int defaultPrefixLength = 4;
if (firstWord == null || secondWord == null) return defaultPrefixLength;

var num = Math.Min(defaultPrefixLength, Math.Min(firstWord.Length, secondWord.Length));
for (var i = 0; i < num; i++)
{
if (firstWord[i] != secondWord[i])
{
return i;
}
}

return num;
}

private static double JaroDistance(string? firstWord, string? secondWord)
{
if (firstWord == null || secondWord == null)
{
return DefaultMatches;
}

var halfRoundedLength = Math.Min(firstWord.Length, secondWord.Length) / 2 +
1;
var firstToSecondWords = GetCommonCharacters(firstWord, secondWord,
halfRoundedLength);
var matches = firstToSecondWords!.Length; if (matches == 0)
{
return DefaultMatches;
}

var secondToFirstWords = GetCommonCharacters(secondWord, firstWord, halfRoundedLength);
if (matches != secondToFirstWords!.Length)
{
return DefaultMatches;
}

var transpositionCounter = 0; for (var i = 0; i < matches; i++)
{
if (firstToSecondWords[i] != secondToFirstWords[i])
{
transpositionCounter++;
}
}
 

transpositionCounter /= 2;
return matches / (3.0 * firstWord.Length) + matches / (3.0 * secondWord.Length) +
(matches - transpositionCounter) / (3.0 * matches);
}

private static StringBuilder? GetCommonCharacters(string? firstWord, string? secondWord, int halfRoundedLength)
{
if (firstWord == null || secondWord == null)
{
return null;
}

var commonCharacters = new StringBuilder();
var comparingWord = new StringBuilder(secondWord); for (var i = 0; i < firstWord.Length; i++)
{
var currentChar = firstWord[i];
for (var j = Math.Max(0, i - halfRoundedLength);
j < Math.Min(i + halfRoundedLength, secondWord.Length); j++)
{
if (comparingWord[j] != currentChar) continue; commonCharacters.Append(currentChar); comparingWord[j] = '*';
break;
}
}

return commonCharacters;
}
}

П4.9. Исходный код класса Correlation

public class Correlation
{
public void CorrelateScores(List<Pupil> pupils, List<string> transcribedElements)
{
var getTextOnly = new Regex(@"[^А-Я\s]+");
for (var i = 0; i < transcribedElements.Count; i++)
{
double minDistance = 0; var minPosition = 0;
foreach (var pupil in pupils)
 
{
var name = pupil.Name.ToUpper().Replace('Ё', 'Е');
var surname = pupil.Surname.ToUpper().Replace('Ё', 'Е'); var currentTranscribedElement =
transcribedElements[i].ToUpper().Replace('Ё', 'Е');
currentTranscribedElement = getTextOnly.Replace(currentTranscribedElement, "").Trim();

var currentNameDistance = JaroWinklerDistance.GetDistance(name,
currentTranscribedElement);

var currentSurnameDistance = JaroWinklerDistance.GetDistance(surname,
currentTranscribedElement);

var totalDistance = JaroWinklerDistance.GetDistance(surname + " " + name,
currentTranscribedElement);

var minDistanceBetween = currentNameDistance > currentSurnameDistance
? currentNameDistance > totalDistance ? currentNameDistance : currentSurnameDistance
: currentSurnameDistance > totalDistance
? currentSurnameDistance
: totalDistance;
if (minDistanceBetween > minDistance)
{
minDistance = minDistanceBetween; minPosition = i;
}
}

pupils[minPosition].Note = transcribedElements[i][transcribedElements[i].LastIndexOf(" ")..].Trim();
}
}
}

П4.10. Исходный код файла Program.cs

using System.Reflection;
using Microsoft.OpenAPI.Models; using VoiceGradeAPI.Services;

var builder = WebApplication.CreateBuilder(args);
 
builder.Services.AddControllers(); builder.Services.AddEndpointsAPIExplorer(); builder.Services.AddSwaggerGen(c =>
{
c.SwaggerDoc("v1", new OpenAPIInfo
{
Version = "0.0.1",
Title = "VoiceGradeAPI v0.0.1",
Description = "API для выставления оценок ученикам с использованием распознавания речи."
});
var xmlFile = $"{Assembly.GetExecutingAssembly().GetName().Name}.xml"; var xmlPath = Path.Combine(AppContext.BaseDirectory, xmlFile); c.IncludeXmlComments(xmlPath);
});

builder.Services.AddSingleton<TranscriberService>(); builder.Services.AddTransient<ProcessingService>();

var app = builder.Build();

// Configure the HTTP request pipeline. if (app.Environment.IsDevelopment())
{
app.UseSwagger();
app.UseSwaggerUI(c => c.SwaggerEndpoint("/swagger/v1/swagger.json", "v1 API")); app.UseHttpsRedirection();
app.UseAuthorization(); app.MapControllers();
}

app.Run();

П4.11. Исходный код файла APIController.cs

using Microsoft.AspNetCore.Mvc; using VoiceGradeAPI.Services;

namespace VoiceGradeAPI.API;

[APIController] [Route("API")]
public class FileUploadController : ControllerBase
{
private readonly string _directoryPath;
private readonly ProcessingService? _processingService; private readonly TranscriberService? _transcriberService;
 
public FileUploadController(ProcessingService processingService, TranscriberService transcriberService)
{
_directoryPath = (Directory.GetCurrentDirectory() + ($@"\UploadedFiles\{Guid.NewGuid()}"));
_processingService = processingService;
_transcriberService = transcriberService;
}

/// <summary>
/// Получает аудиофайл (MP3/WAV/M4A) и список учеников (JSON/XML)
/// </summary>
/// <remarks>
/// Пример JSON элемента файла:
///
///	POST API/upload
///	{
///	"Name": "Илья",
///	"Surname": "Воробьев",
///	"MiddleName": "Викторович"
///	},
///
/// Аналогично оформляется XML документ.
/// Загружаемый аудиофайл должен быть в формате mp3, wav, m4a.
/// В качестве ответа будет отправлен файл в формате JSON/XML, с проставленными оценками
/// </remarks>
/// <response code="200"> Итоговый файл создан</response>
/// <response code="400"> Проблемы с загрузкой файлов</response>
/// <returns>Возвращает файл с учениками и их отметками (json/xml)</returns>
// POST: API/upload

[HttpPost("upload")]
public async Task<ActionResult> UploadFiles(IFormFile file1, IFormFile file2)
{

if (file1 == null) throw new ArgumentNullException(nameof(file1)); if (file2 == null) throw new ArgumentNullException(nameof(file2));

if (!Directory.Exists(_directoryPath)) Directory.CreateDirectory(_directoryPath);
var downloadedFiles = new List<string>();

foreach (var file in new List<IFormFile> { file1, file2 })
{
var originalName = Path.GetFileName(file.FileName);
var filePath = Path.Combine(_directoryPath, originalName); await using (var stream = System.IO.File.Create(filePath))
 
{
await file.CopyToAsync(stream);
}

downloadedFiles.Add(filePath);
}

var res = _processingService?.GetResultedFile(downloadedFiles,
_transcriberService);
var resultFileName = res[(res.LastIndexOf("\\") + 1)..]; var bytes = await System.IO.File.ReadAllBytesAsync(res); return File(bytes, "application/json", resultFileName);
}
}

П4.12. Исходный код класса ProcessingService

public class ProcessingService
{
private IFileService _fileService; private TextParser _parser; private Correlation _correlation;

public ProcessingService()
{
_parser = new TextParser();
_correlation = new Correlation();
}

public string GetResultedFile(List<string> files, TranscriberService transcriberService)
{
string audioFile = "", pupilsFile = ""; foreach (var file in files)
{
var info = new FileInfo(file); switch (info.Extension)
{
case ".json":
_fileService = new JsonService(); pupilsFile = file;
break; case ".xml":
_fileService = new XmlService(); pupilsFile = file;
break;
case ".wav": case ".mp3": case ".m4a": audioFile = file;
 
break;
}
}

if (pupilsFile == "") throw new BadHttpRequestException("Need to load file with pupils");
if (audioFile == "") throw new BadHttpRequestException("Need to load audiofile");

AudioConverter converter = new MpConverter(audioFile); audioFile = converter.ConvertAudio();
var pupils = _fileService.ReadFile(pupilsFile);
var allData = TranscriberService.TranscribeAudio(audioFile); var transcribedNames = _parser.ParseData(allData);
_correlation.CorrelateScores(pupils, transcribedNames); var createdFilePath = _fileService.CreateFile(pupils); return createdFilePath;
}
}

П4.13. Исходный код класса TranscriberModel

public sealed class TranscriberModel
{
private readonly Model _model; public Model Model => _model;

TranscriberModel()
{
_model = new Model(@"AudioModels/vosk-model-ru-0.22_1");
}

private static readonly Lazy<TranscriberModel> Lazy = new(() => new TranscriberModel());

public static TranscriberModel Instance => Lazy.Value;
}
